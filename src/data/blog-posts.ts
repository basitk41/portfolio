import { BlogPost } from "@/types";

export const blogPosts: BlogPost[] = [
  {
    id: "leveraging-ai-development",
    title: "Leveraging AI in Modern Frontend Development",
    summary:
      "Explore how AI tools are transforming the frontend development workflow and making developers more productive.",
    content: `
# Leveraging AI in Modern Frontend Development

In recent years, AI has become an indispensable tool for frontend developers. From code completion to design assistance, AI is revolutionizing how we build user interfaces. Let's explore how you can leverage AI to enhance your frontend development workflow.

## Code Assistance with AI

Modern AI coding assistants like GitHub Copilot, ChatGPT, Claude, and Amazon CodeWhisperer have transformed the development experience. These tools can:

- Generate boilerplate code
- Suggest function implementations
- Help debug complex issues
- Write unit tests based on your code
- Translate between programming languages and frameworks

I've found that using AI assistants can reduce the time spent on repetitive coding tasks by up to 40%, allowing more focus on architecture and problem-solving.

## Optimizing Performance with AI

AI tools are now capable of analyzing your application and suggesting optimizations:

\`\`\`javascript
// Before optimization
const handleSearch = (query) => {
  const results = data.filter(item => 
    item.name.includes(query) || 
    item.description.includes(query)
  );
  setSearchResults(results);
};

// After AI-suggested optimization
const handleSearch = useCallback(
  debounce((query) => {
    if (!query.trim()) {
      setSearchResults([]);
      return;
    }
    
    const queryLower = query.toLowerCase();
    const results = data.filter(item => 
      item.name.toLowerCase().includes(queryLower) || 
      item.description.toLowerCase().includes(queryLower)
    );
    setSearchResults(results);
  }, 300),
  [data]
);
\`\`\`

## AI-Driven UI/UX Improvements

AI design tools can now analyze your application's interface and suggest improvements for better user experience:

- Accessibility enhancements
- Color contrast optimizations
- Layout improvements
- Responsive design suggestions

## Practical Tips for Integrating AI Into Your Workflow

1. **Start with clear requirements**: AI works best when you provide clear context and specifications.

2. **Review and refine AI output**: Always critically review code generated by AI tools before implementing it.

3. **Use AI for learning**: Ask AI tools to explain complex concepts or to provide alternative approaches to problems.

4. **Combine human creativity with AI efficiency**: Use AI for the repetitive parts, but keep the creative and architectural decisions to yourself.

5. **Stay updated with AI capabilities**: The AI landscape is evolving rapidly; regularly explore new tools and features.

## Conclusion

AI isn't replacing frontend developersâ€”it's making us more powerful. By embracing these tools thoughtfully, we can focus more on creativity and problem-solving while letting AI handle the mundane aspects of coding.

As we move forward, the synergy between human creativity and AI assistance will continue to reshape frontend development, making it more efficient, accessible, and innovative.
`,
    author: "Basit Ali",
    date: "2025-02-15",
    readTime: 8,
    tags: ["AI", "Frontend Development", "Web Development", "JavaScript"],
    image: "./images/blog/ai-frontend.png",
    featured: true,
  },
  {
    id: "understanding-modern-llms",
    title: "Understanding Modern LLMs: A Developer's Guide",
    summary:
      "A comprehensive overview of Large Language Models (LLMs), how they work, and their implications for developers.",
    content: `
# Understanding Modern LLMs: A Developer's Guide

Large Language Models (LLMs) like GPT-4, Claude, and LLaMA have transformed how we interact with AI. As a developer, understanding these models can open new possibilities for your applications. Let's dive into how LLMs work and how you can leverage them.

## How LLMs Work

Modern LLMs are based on the Transformer architecture, which uses self-attention mechanisms to process and generate text. Here's a simplified explanation of how they work:

1. **Tokenization**: Text is broken down into tokens (words or parts of words).
2. **Embeddings**: These tokens are converted into numerical vectors.
3. **Attention layers**: The model processes these vectors through multiple layers of attention mechanisms.
4. **Prediction**: The model predicts the next token based on patterns learned during training.

The scale of these models is staggering - GPT-4 has hundreds of billions of parameters, allowing it to capture complex patterns in language.

## Key Capabilities of Modern LLMs

- **Text Generation**: Creating human-like text for various purposes
- **Translation**: Converting text between languages
- **Summarization**: Condensing lengthy texts
- **Code Generation**: Writing and explaining code
- **Reasoning**: Solving problems through step-by-step logic
- **Instruction Following**: Performing tasks based on specific directions

## Practical Applications in Development

### 1. Enhancing Search with Semantic Understanding

LLMs can improve search functionality by understanding the semantic meaning behind queries:

\`\`\`javascript
// Using an LLM to enhance search results
async function semanticSearch(query, documents) {
  // Get vector embeddings for the query using an LLM API
  const queryEmbedding = await getEmbedding(query);
  
  // Compare query embedding with document embeddings
  const results = documents.map(doc => ({
    document: doc,
    relevance: cosineSimilarity(queryEmbedding, doc.embedding)
  }));
  
  return results.sort((a, b) => b.relevance - a.relevance);
}
\`\`\`

### 2. Generating UI Components

LLMs can help generate UI components based on descriptions:

\`\`\`jsx
// Example: Using an LLM to generate a React component
const promptToComponent = async (description) => {
  const response = await llmAPI.complete({
    prompt: \`Create a React functional component with TypeScript for: \${description}. Use Tailwind CSS for styling.\`,
    temperature: 0.2,
    max_tokens: 1000
  });
  
  // The response would contain code that you could parse and use
  return response.text;
};

// Usage
const cardComponent = await promptToComponent(
  "A card component that displays a product with an image, title, price, and an 'Add to Cart' button."
);
\`\`\`

### 3. Data Analysis and Visualization

LLMs can help interpret data and suggest appropriate visualizations:

\`\`\`javascript
// Using an LLM to analyze data and suggest visualizations
async function analyzeDataset(dataset) {
  const sample = dataset.slice(0, 10);
  
  const analysis = await llmAPI.complete({
    prompt: \`Analyze this dataset and suggest appropriate visualizations: \${JSON.stringify(sample)}\`,
    temperature: 0.3,
    max_tokens: 1000
  });
  
  return analysis.text;
}
\`\`\`

## Best Practices for Working with LLMs

1. **Provide Clear Context**: LLMs perform best when given clear, specific instructions.

2. **Implement Guardrails**: Always validate LLM outputs before using them in production systems.

3. **Consider Ethical Implications**: Be mindful of biases and potential misuse of the technology.

4. **Use Retrieval-Augmented Generation (RAG)**: Combine LLMs with retrieval systems to provide factual, up-to-date information.

5. **Optimize for Cost and Latency**: LLM API calls can be expensive and slow; cache results when possible.

## The Future of LLMs in Development

As LLMs continue to evolve, we can expect:

- More specialized models optimized for specific tasks
- Improved multimodal capabilities (text, image, audio)
- Better reasoning and planning abilities
- More efficient models that can run locally
- Deeper integration with development environments

## Conclusion

LLMs represent a paradigm shift in how we can integrate AI into our applications. By understanding their capabilities and limitations, developers can leverage these powerful tools to create more intelligent, user-friendly applications.

As with any technology, the key is to use LLMs thoughtfully, with proper planning and guardrails, to enhance rather than replace human creativity and judgment.
`,
    author: "Basit Ali",
    date: "2025-01-20",
    readTime: 10,
    tags: ["AI", "LLM", "Machine Learning", "NLP"],
    image: "./images/blog/llm-guide.webp",
    featured: true,
  },
  {
    id: "micro-frontends-architecture",
    title: "Micro Frontends: Scaling Your Frontend Architecture",
    summary:
      "Explore the principles, benefits, and implementation strategies of micro frontend architecture for large-scale applications.",
    content: `
# Micro Frontends: Scaling Your Frontend Architecture

As web applications grow in complexity, traditional monolithic frontend architectures can become challenging to maintain and scale. Micro frontends represent an architectural approach that extends the microservices concept to frontend development. This post explores how micro frontends can help teams scale their frontend architecture effectively.

## What Are Micro Frontends?

Micro frontends are an architectural pattern where a frontend application is decomposed into individual, semi-independent "microapps" that can be built, tested, and deployed independently. Each micro frontend corresponds to a distinct feature or business domain within the larger application.

The core principles include:

1. **Independent teams**: Teams can work autonomously on different parts of the application
2. **Technology agnostic**: Different micro frontends can use different frameworks if needed
3. **Isolation**: Bugs in one micro frontend shouldn't affect others
4. **Team code ownership**: Teams own their micro frontend from database to user interface
5. **Native browser experience**: The final result should feel like a single cohesive application

## Implementation Approaches

There are several ways to implement micro frontends:

### 1. Build-Time Integration

Components are published as packages and included in the main application during build time:

\`\`\`javascript
// package.json
{
  "dependencies": {
    "@company/header": "1.0.0",
    "@company/product-list": "1.2.0",
    "@company/checkout": "0.9.0"
  }
}
\`\`\`

**Pros**: Simple, good performance
**Cons**: Requires rebuilding and redeploying the entire application for updates

### 2. Runtime Integration via iframes

Each micro frontend runs in its own iframe:

\`\`\`html
<iframe src="https://checkout.example.com" id="checkout"></iframe>
\`\`\`

**Pros**: Strong isolation, independent deployment
**Cons**: UX challenges, communication complexity

### 3. Runtime Integration via JavaScript

Using a frontend orchestrator that loads micro frontends at runtime:

\`\`\`javascript
// Simplified example of a micro frontend loader
const microFrontendLoader = {
  async load(name, elementId, props = {}) {
    // Fetch the manifest to get the latest version
    const manifest = await fetch('/manifest.json').then(res => res.json());
    const url = manifest[name];
    
    // Load the micro frontend script
    const script = document.createElement('script');
    script.src = url;
    document.head.appendChild(script);
    
    // Wait for it to load and then mount it
    script.onload = () => {
      window.microFrontends[name].mount(elementId, props);
    };
  }
};

// Usage
microFrontendLoader.load('checkout', 'checkout-container', { 
  userId: 'user123', 
  cartId: 'cart456' 
});
\`\`\`

**Pros**: Better UX, independent deployment
**Cons**: More complex to set up, potential for conflicts

### 4. Web Components

Using custom elements for better encapsulation:

\`\`\`javascript
// Defining a micro frontend as a Web Component
class ProductList extends HTMLElement {
  connectedCallback() {
    this.render();
  }
  
  render() {
    this.innerHTML = '<div>Product list is loading...</div>';
    
    // Load the actual micro frontend
    import('/product-list/bundle.js')
      .then(module => {
        module.render(this, {
          category: this.getAttribute('category')
        });
      });
  }
}

customElements.define('product-list', ProductList);

// Usage in HTML
<product-list category="electronics"></product-list>
\`\`\`

**Pros**: Good encapsulation, web standards
**Cons**: Limited browser support for some features

## Communication Between Micro Frontends

Communication is crucial in a micro frontend architecture. Common patterns include:

### 1. Custom Events

\`\`\`javascript
// Micro frontend A: Dispatching an event
window.dispatchEvent(new CustomEvent('productAdded', {
  detail: { productId: '123', name: 'Keyboard', price: 59.99 }
}));

// Micro frontend B: Listening for the event
window.addEventListener('productAdded', (event) => {
  console.log('Product added:', event.detail);
  // Update cart or perform other actions
});
\`\`\`

### 2. Shared State Management

Using a centralized store that micro frontends can subscribe to:

\`\`\`javascript
// A simple shared state implementation
const createSharedStore = () => {
  let state = {};
  const listeners = new Map();
  
  const getState = () => ({ ...state });
  
  const setState = (newState) => {
    state = { ...state, ...newState };
    
    // Notify all listeners
    for (const [name, callback] of listeners) {
      callback(state);
    }
  };
  
  const subscribe = (name, callback) => {
    listeners.set(name, callback);
    callback(state);
    
    return () => {
      listeners.delete(name);
    };
  };
  
  return { getState, setState, subscribe };
};

// Create a shared store
const store = createSharedStore();

// Micro frontend A: Update state
const addToCart = (product) => {
  const currentState = store.getState();
  const currentCart = currentState.cart || [];
  
  store.setState({
    cart: [...currentCart, product]
  });
};

// Micro frontend B: Subscribe to changes
const unsubscribe = store.subscribe('cart-display', (state) => {
  console.log('Cart updated:', state.cart);
  // Update UI
});

// Clean up when component unmounts
unsubscribe();
\`\`\`

## Challenges and Solutions

### 1. Styling Consistency

**Challenge**: Maintaining consistent styling across micro frontends.

**Solutions**:
- Shared design system packages
- CSS-in-JS with theme providers
- CSS custom properties (variables)

\`\`\`javascript
// Shared styles with CSS variables
:root {
  --primary-color: #0070f3;
  --secondary-color: #ff4081;
  --font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif;
  --spacing-unit: 8px;
}

// Each micro frontend uses these variables
.checkout-button {
  background-color: var(--primary-color);
  padding: calc(var(--spacing-unit) * 2);
  font-family: var(--font-family);
}
\`\`\`

### 2. Performance Concerns

**Challenge**: Multiple JavaScript bundles can impact loading performance.

**Solutions**:
- Module federation for shared dependencies
- Progressive loading strategies
- Efficient caching policies
- Performance budgets per micro frontend

### 3. Testing

**Challenge**: Testing the integration between micro frontends.

**Solutions**:
- Contract testing between micro frontends
- End-to-end tests for critical user journeys
- Synthetic monitoring in production

## Real-World Example: S&P Capital IQ Pro

At S&P Global, I contributed to building the Capital IQ Pro platform using a micro frontend architecture. Here's a simplified overview of our approach:

1. We decomposed the application into domain-based micro frontends (market data, company profiles, analytics, etc.)
2. Each team owned their micro frontend end-to-end
3. We used a shared design system to ensure UI consistency
4. Module federation enabled sharing of common components and dependencies
5. A centralized shell application handled routing and authentication

This approach allowed dozens of teams to work simultaneously without stepping on each other's toes, while maintaining a cohesive user experience.

## Conclusion

Micro frontends offer a powerful approach to scaling frontend architecture, especially for large organizations with multiple teams. While they add some complexity, the benefits of autonomous teams, independent deployments, and technology flexibility can significantly improve development velocity and application maintainability.

As with any architectural pattern, the key is to apply micro frontends thoughtfully, based on your organization's specific needs. Not every application requires the complexity of micro frontends, but for large-scale applications with multiple teams, they can be a game-changer.
`,
    author: "Basit Ali",
    date: "2025-03-05",
    readTime: 12,
    tags: ["Frontend Architecture", "Micro Frontends", "React", "JavaScript"],
    image: "./images/blog/micro-frontends.webp",
    featured: false,
  },
  {
    id: "generative-ai-daily-life",
    title: "How Generative AI Can Transform Your Daily Life",
    summary:
      "Practical ways to use generative AI tools like ChatGPT, DALL-E, and Midjourney to enhance productivity and creativity in everyday tasks.",
    content: `
# How Generative AI Can Transform Your Daily Life

Generative AI has evolved rapidly, moving from research labs to practical tools that anyone can use. Technologies like ChatGPT, Claude, DALL-E, and Midjourney are no longer just novelties but powerful assistants that can transform how we work, create, and solve problems. Here's how you can leverage these tools in your daily life.

## Writing Enhancement

AI can help with various writing tasks:

### Email Drafting

Instead of staring at a blank screen, use an AI assistant to generate a draft:

> *Prompt: "Draft a polite email to my client explaining that the project timeline needs to be extended by two weeks due to unexpected technical challenges with the payment gateway integration."*

The AI will create a professional draft that you can personalize and refine.

### Content Creation

Whether you're working on a blog post, documentation, or creative writing, AI can help:

> *Prompt: "Create an outline for a blog post about the benefits of TypeScript in large-scale web applications."*

This gives you a structured starting point that you can expand upon with your own expertise.

### Editing and Proofreading

AI can help polish your writing:

> *Prompt: "Review this paragraph for clarity, conciseness, and grammar issues: [your text]"*

## Creative Inspiration

### Visual Design

Tools like DALL-E 3 and Midjourney can generate images based on textual descriptions:

> *Prompt: "Create a minimalist logo for a tech startup called 'Horizon' that specializes in cloud computing services. The logo should incorporate subtle cloud imagery without being literal, using a color gradient from deep blue to teal."*

These tools are excellent for brainstorming visual concepts before working with a professional designer.

### Problem-Solving

When facing a challenging problem, AI can offer fresh perspectives:

> *Prompt: "I need to improve user engagement on my website's blog section. What are some creative approaches I haven't considered yet?"*

## Coding Assistance

As a developer, AI tools can significantly boost your productivity:

### Code Generation

> *Prompt: "Write a React custom hook that manages form state with validation for email, password, and optional user profile information."*

### Bug Fixing

> *Prompt: "Debug this code that's causing an infinite loop: [your code]"*

### Learning New Technologies

> *Prompt: "Explain how React Server Components work and provide a simple example of when to use them versus client components."*

## Daily Productivity

### Meeting Preparation

> *Prompt: "Create a meeting agenda for a 30-minute project kickoff with a new client for a web application project. Include key points to cover and questions to ask."*

### Decision Making

> *Prompt: "I'm trying to decide between using AWS Lambda or a traditional server setup for my application that handles periodic data processing. Help me compare the pros and cons of each approach for this use case."*

### Information Summarization

> *Prompt: "Summarize the key points from this technical article: [article text or link]"*

## Personal Development

### Learning Concepts

> *Prompt: "Explain the concept of microservices architecture to me as if I'm a frontend developer with no backend experience."*

### Creating Learning Plans

> *Prompt: "Create a 30-day learning plan to help me transition from frontend development to full-stack development, focusing on Node.js and Express."*

## Practical Tips for Getting the Best Results

### 1. Be Specific in Your Prompts

The more specific your prompt, the better the output:

- **Vague prompt**: "Write some code for a website."
- **Specific prompt**: "Write HTML and CSS for a responsive navigation menu that collapses into a hamburger menu on mobile devices, using Flexbox for layout."

### 2. Iterative Refinement

Don't expect perfect results on the first try. Use an iterative approach:

1. Start with an initial prompt
2. Review the response
3. Ask for specific refinements
4. Repeat until satisfied

### 3. Provide Context

When appropriate, include relevant background information:

> *Prompt: "I'm working with a React application that uses Redux for state management. The app is experiencing performance issues when updating large lists. The current implementation uses a single reducer for all data. Suggest some optimization strategies."*

### 4. Use System Instructions

For complex tasks, start with clear system instructions:

> *"I want you to act as a senior TypeScript developer reviewing my code. Focus on type safety, performance, and adherence to best practices. Be direct and concise in your feedback."*

### 5. Combine AI Tools

Different AI tools have different strengths. For instance:

1. Use ChatGPT to draft content for your website
2. Use DALL-E to generate imagery to accompany the content
3. Use Claude to review and refine the final result

## Ethical Considerations

As we incorporate these powerful tools into our daily lives, it's important to consider:

1. **Content Verification**: Always verify factual information provided by AI
2. **Attribution**: Disclose AI-generated content when appropriate
3. **Over-reliance**: Maintain your own critical thinking and decision-making skills
4. **Privacy**: Be cautious about sharing sensitive information with AI systems

## Conclusion

Generative AI isn't about replacing human creativity or expertiseâ€”it's about amplifying it. By thoughtfully incorporating these tools into your workflow, you can save time on routine tasks, overcome creative blocks, and focus your energy on the aspects of your work that most benefit from human judgment and expertise.

As these technologies continue to evolve, the most valuable skill will be knowing how to effectively collaborate with AIâ€”understanding its strengths, compensating for its limitations, and directing it toward the outcomes you want to achieve.

What everyday tasks are you using AI for? I'd love to hear your experiences in the comments.
`,
    author: "Basit Ali",
    date: "2025-02-25",
    readTime: 9,
    tags: ["AI", "Productivity", "Creativity", "Technology", "ChatGPT"],
    image: "./images/blog/generative-ai.webp",
    featured: true,
  },
  {
    id: "react-evolution",
    title: "The Evolution of React: From Class Components to Server Components",
    summary:
      "A comprehensive look at how React has evolved over the years, the paradigm shifts it introduced, and how the latest Server Components are changing frontend development.",
    content: `
  # The Evolution of React: From Class Components to Server Components
  
  React has undergone a remarkable evolution since its initial release in 2013. What started as a library for building user interfaces with class components has transformed into a comprehensive ecosystem that now includes Server Components. This journey represents not just technical changes, but fundamental shifts in how we think about frontend development.
  
  ## The Class Component Era (2013-2018)
  
  When React was first introduced, class components were the primary way to create stateful components:
  
  \`\`\`jsx
  class Counter extends React.Component {
    constructor(props) {
      super(props);
      this.state = { count: 0 };
      this.increment = this.increment.bind(this);
    }
    
    increment() {
      this.setState({ count: this.state.count + 1 });
    }
    
    render() {
      return (
        <div>
          <p>Count: {this.state.count}</p>
          <button onClick={this.increment}>Increment</button>
        </div>
      );
    }
  }
  \`\`\`
  
  Class components had several characteristics:
  - Verbose syntax with constructors and method binding
  - Lifecycle methods like componentDidMount and componentDidUpdate
  - No easy way to reuse stateful logic between components
  - "this" binding confusion
  - Large component files as applications grew
  
  Despite these challenges, class components provided a structured way to build applications and formed the foundation of React's component model.
  
  ## The Hooks Revolution (2019)
  
  React 16.8 introduced Hooks, fundamentally changing how developers write React components:
  
  \`\`\`jsx
  function Counter() {
    const [count, setCount] = useState(0);
    
    return (
      <div>
        <p>Count: {count}</p>
        <button onClick={() => setCount(count + 1)}>Increment</button>
      </div>
    );
  }
  \`\`\`
  
  Hooks brought several advantages:
  - More concise, function-based components
  - Ability to reuse stateful logic through custom hooks
  - Better organization of related code
  - Fewer bugs related to "this" binding
  - Improved TypeScript integration
  
  Hooks represented a paradigm shift in React development, moving from class-oriented to function-oriented programming. Custom hooks enabled powerful patterns for code reuse:
  
  \`\`\`jsx
  function useWindowSize() {
    const [size, setSize] = useState({ width: window.innerWidth, height: window.innerHeight });
    
    useEffect(() => {
      const handleResize = () => {
        setSize({ width: window.innerWidth, height: window.innerHeight });
      };
      
      window.addEventListener('resize', handleResize);
      return () => window.removeEventListener('resize', handleResize);
    }, []);
    
    return size;
  }
  \`\`\`
  
  ## The Concurrent Era (2021-2022)
  
  React 18 introduced the concept of concurrent rendering, allowing React to prepare multiple versions of the UI at the same time:
  
  \`\`\`jsx
  // Creating a concurrent root
  const root = ReactDOM.createRoot(document.getElementById('root'));
  root.render(<App />);
  \`\`\`
  
  Key features included:
  - Automatic batching of state updates
  - Transitions for marking updates as non-urgent
  - Suspense for managing loading states
  - Streaming server rendering
  
  This was a foundational change to React's internal architecture, enabling new capabilities like:
  
  \`\`\`jsx
  function SearchResults({ query }) {
    const [isPending, startTransition] = useTransition();
    const [searchQuery, setSearchQuery] = useState(query);
    
    function handleChange(e) {
      // Mark state update as non-urgent
      startTransition(() => {
        setSearchQuery(e.target.value);
      });
    }
    
    return (
      <div>
        <input value={searchQuery} onChange={handleChange} />
        {isPending ? <Spinner /> : <Results query={searchQuery} />}
      </div>
    );
  }
  \`\`\`
  
  ## The Server Components Revolution (2023-Present)
  
  React Server Components (RSC) represent the most significant paradigm shift since hooks, blurring the line between server and client:
  
  \`\`\`jsx
  // This component runs on the server only
  async function ProductDetails({ id }) {
    // Direct database access - no API calls needed
    const product = await db.products.findUnique({ where: { id } });
    
    return (
      <div>
        <h1>{product.name}</h1>
        <p>{product.description}</p>
        <AddToCartButton id={product.id} /> {/* Client Component */}
      </div>
    );
  }
  
  // This component will be rendered on the client
  'use client';
  function AddToCartButton({ id }) {
    return <button onClick={() => addToCart(id)}>Add to Cart</button>;
  }
  \`\`\`
  
  Server Components provide several groundbreaking benefits:
  - Zero bundle size impact for server-only code
  - Direct access to backend resources
  - Automatic code splitting
  - Streaming rendering for improved performance
  - Progressive enhancement built in
  
  The mental model changes from "client-side application with API calls" to "unified application that spans server and client." This brings several performance and developer experience improvements:
  
  1. Reduced JavaScript bundle sizes
  2. Faster initial page loads
  3. Better SEO by default
  4. Simplified data fetching patterns
  5. Improved security by keeping sensitive operations server-side
  
  ## What's Next for React?
  
  The React team has several initiatives in progress:
  
  1. **React Compiler (Formerly React Forget)**: Automatic memoization to eliminate the need for manual optimizations
  2. **New React Documentation**: Complete rewrite focusing on hooks and modern practices
  3. **Asset Loading Improvements**: Better ways to manage images and other assets
  4. **Improved Streaming Capabilities**: For even better user experiences
  
  ## Embracing the Evolution
  
  Each stage in React's evolution has brought improved developer experience, better performance, and new capabilities. To stay current with React development:
  
  1. Focus on function components and hooks for all new development
  2. Learn about Server Components and the patterns they enable
  3. Understand concurrent features like useTransition
  4. Refactor large class components gradually
  5. Leverage the React ecosystem of libraries and tools
  
  The evolution of React reflects broader trends in frontend development: a move toward functional programming, closer integration between frontend and backend, and a focus on both developer experience and end-user performance.
  
  By understanding this journey, you can better appreciate where React is headed and how to leverage its latest features in your applications.
  `,
    author: "Basit Ali",
    date: "2025-01-10",
    readTime: 13,
    tags: ["React", "Frontend Development", "Server Components", "JavaScript"],
    image: "./images/blog/react-evolution.png",
    featured: false,
  },
  {
    id: "state-management-beyond-redux",
    title: "State Management in 2025: Beyond Redux",
    summary:
      "Exploring modern state management solutions including Zustand, Jotai, Recoil, and how the Context API has matured, with practical examples and performance comparisons.",
    content: `
  # State Management in 2025: Beyond Redux
  
  State management has evolved significantly since the early days of React. While Redux dominated the landscape for years, we've seen a proliferation of lighter, more specialized alternatives. This post explores the current state management landscape and helps you choose the right solution for your needs.
  
  ## The Evolution of State Management
  
  Redux emerged in 2015 as a predictable state container inspired by Flux architecture. It introduced concepts like:
  - A single store for application state
  - Pure reducer functions for state updates
  - Action objects to describe changes
  - Middleware for side effects
  
  While Redux provided structure and predictability, it came with drawbacks:
  - Verbose boilerplate code
  - Steep learning curve
  - Complexity for simple use cases
  - Performance concerns for large applications
  
  This led to a wave of innovation in state management libraries.
  
  ## Modern State Management Options
  
  ### React's Built-in Solutions
  
  #### 1. useState + useReducer
  
  For simpler applications, React's built-in hooks often suffice:
  
  \`\`\`jsx
  function Counter() {
    const [count, setCount] = useState(0);
    
    return (
      <div>
        <p>Count: {count}</p>
        <button onClick={() => setCount(count + 1)}>Increment</button>
      </div>
    );
  }
  \`\`\`
  
  For more complex state logic, useReducer provides Redux-like structure:
  
  \`\`\`jsx
  function reducer(state, action) {
    switch (action.type) {
      case 'increment':
        return { count: state.count + 1 };
      case 'decrement':
        return { count: state.count - 1 };
      default:
        throw new Error();
    }
  }
  
  function Counter() {
    const [state, dispatch] = useReducer(reducer, { count: 0 });
    
    return (
      <div>
        <p>Count: {state.count}</p>
        <button onClick={() => dispatch({ type: 'increment' })}>Increment</button>
        <button onClick={() => dispatch({ type: 'decrement' })}>Decrement</button>
      </div>
    );
  }
  \`\`\`
  
  #### 2. Context API
  
  For sharing state across components, the Context API has matured significantly:
  
  \`\`\`jsx
  // Create a context
  const ThemeContext = createContext();
  
  // Provider component
  function ThemeProvider({ children }) {
    const [theme, setTheme] = useState('light');
    
    const toggleTheme = () => {
      setTheme(theme === 'light' ? 'dark' : 'light');
    };
    
    return (
      <ThemeContext.Provider value={{ theme, toggleTheme }}>
        {children}
      </ThemeContext.Provider>
    );
  }
  
  // Consumer component
  function ThemedButton() {
    const { theme, toggleTheme } = useContext(ThemeContext);
    
    return (
      <button 
        style={{ background: theme === 'light' ? '#fff' : '#333', color: theme === 'light' ? '#333' : '#fff' }}
        onClick={toggleTheme}
      >
        Toggle Theme
      </button>
    );
  }
  \`\`\`
  
  ### Zustand: Simplicity Meets Power
  
  Zustand has gained significant popularity due to its simplicity and flexibility:
  
  \`\`\`jsx
  import create from 'zustand';
  
  // Create a store
  const useStore = create((set) => ({
    bears: 0,
    increasePopulation: () => set((state) => ({ bears: state.bears + 1 })),
    removeAllBears: () => set({ bears: 0 }),
  }));
  
  // Use the store in a component
  function BearCounter() {
    const bears = useStore((state) => state.bears);
    const increasePopulation = useStore((state) => state.increasePopulation);
    
    return (
      <div>
        <h1>{bears} bears around here...</h1>
        <button onClick={increasePopulation}>Add a bear</button>
      </div>
    );
  }
  \`\`\`
  
  Zustand's advantages include:
  - Minimal boilerplate
  - No providers required
  - Built-in immer integration for easy state updates
  - TypeScript support
  - Middleware system for side effects
  - Optimized re-rendering
  
  ### Jotai: Atomic State Management
  
  Jotai takes inspiration from Recoil but with a simpler API:
  
  \`\`\`jsx
  import { atom, useAtom } from 'jotai';
  
  // Create atoms
  const countAtom = atom(0);
  const doubleCountAtom = atom(
    (get) => get(countAtom) * 2
  );
  
  function Counter() {
    const [count, setCount] = useAtom(countAtom);
    const [doubleCount] = useAtom(doubleCountAtom);
    
    return (
      <div>
        <h1>Count: {count}</h1>
        <h2>Double count: {doubleCount}</h2>
        <button onClick={() => setCount(c => c + 1)}>Increment</button>
      </div>
    );
  }
  \`\`\`
  
  Jotai's benefits include:
  - Atomic approach to state
  - No context providers needed
  - Excellent TypeScript support
  - Lower re-rendering overhead
  - Integration with React Suspense
  
  ### Recoil: Facebook's State Management Solution
  
  Recoil brings a more sophisticated approach focused on derived state:
  
  \`\`\`jsx
  import { atom, selector, useRecoilState, useRecoilValue } from 'recoil';
  
  // Define atoms and selectors
  const countAtom = atom({
    key: 'countAtom',
    default: 0,
  });
  
  const doubleCountSelector = selector({
    key: 'doubleCount',
    get: ({get}) => {
      return get(countAtom) * 2;
    },
  });
  
  function Counter() {
    const [count, setCount] = useRecoilState(countAtom);
    const doubleCount = useRecoilValue(doubleCountSelector);
    
    return (
      <div>
        <h1>Count: {count}</h1>
        <h2>Double count: {doubleCount}</h2>
        <button onClick={() => setCount(count + 1)}>Increment</button>
      </div>
    );
  }
  \`\`\`
  
  Recoil excels in:
  - Complex derived state calculations
  - Asynchronous data queries
  - State persistence
  - Time-travel debugging
  - React Suspense integration
  
  ## Redux Today: Modern Redux with Redux Toolkit
  
  Redux has evolved with Redux Toolkit (RTK), addressing many of its original pain points:
  
  \`\`\`jsx
  import { createSlice, configureStore } from '@reduxjs/toolkit';
  import { useDispatch, useSelector } from 'react-redux';
  
  // Create a slice
  const counterSlice = createSlice({
    name: 'counter',
    initialState: { value: 0 },
    reducers: {
      incremented: state => {
        // Immer allows "mutating" syntax
        state.value += 1;
      },
      decremented: state => {
        state.value -= 1;
      }
    }
  });
  
  // Export actions and reducer
  export const { incremented, decremented } = counterSlice.actions;
  
  // Create store
  const store = configureStore({
    reducer: {
      counter: counterSlice.reducer
    }
  });
  
  // Component
  function Counter() {
    const count = useSelector(state => state.counter.value);
    const dispatch = useDispatch();
    
    return (
      <div>
        <p>Count: {count}</p>
        <button onClick={() => dispatch(incremented())}>Increment</button>
        <button onClick={() => dispatch(decremented())}>Decrement</button>
      </div>
    );
  }
  \`\`\`
  
  RTK improvements include:
  - Drastically reduced boilerplate
  - Built-in Immer for easier state updates
  - Integrated Redux DevTools
  - RTK Query for data fetching and caching
  
  ## Performance Comparison
  
  | Library | Bundle Size | Setup Complexity | Re-render Efficiency | Learning Curve |
  |---------|-------------|------------------|----------------------|----------------|
  | useState + Context | 0 KB (built-in) | Medium | Medium | Low |
  | Redux + RTK | ~15 KB | Medium | High with memoization | Medium |
  | Zustand | ~3 KB | Low | High | Low |
  | Jotai | ~4 KB | Low | Very High | Low |
  | Recoil | ~20 KB | Medium | High | Medium |
  
  ## Choosing the Right Solution
  
  There's no one-size-fits-all solution. Consider these guidelines:
  
  1. **Small to medium applications**:
     - useState + useReducer + Context API
     - Zustand for slightly more complex needs
  
  2. **Medium to large applications**:
     - Zustand for general purpose state
     - Jotai for fine-grained, atomic updates
     - Redux Toolkit when you need a mature ecosystem
  
  3. **Complex applications with derived state**:
     - Recoil for complex data relationships
     - Jotai for atomic approach with less boilerplate
  
  4. **Applications with heavy data requirements**:
     - Redux Toolkit with RTK Query
     - TanStack Query (React Query) combined with any state solution
  
  ## The Future of State Management
  
  The trend is clear: simpler APIs, less boilerplate, and more targeted solutions. Looking forward, we can expect:
  
  1. **Server Components Integration**: State management solutions adapting to React Server Components
  2. **Compiler Optimizations**: Tools like React Compiler automatically optimizing state updates
  3. **Fine-grained Reactivity**: More libraries adopting signal-like patterns for update granularity
  4. **AI-enhanced Developer Experience**: Smarter state debugging and optimization tools
  
  ## Conclusion
  
  The state management landscape has matured beyond Redux monoliths to a rich ecosystem of specialized tools. This gives developers the freedom to choose solutions that match their specific requirements rather than forcing all applications into the same pattern.
  
  Whether you prefer the simplicity of Zustand, the atomic approach of Jotai, or the robustness of Redux Toolkit, today's state management options offer better developer experiences without sacrificing performance. The key is understanding the trade-offs and selecting the right tool for your specific use case.
  `,
    author: "Basit Ali",
    date: "2025-02-18",
    readTime: 12,
    tags: [
      "React",
      "State Management",
      "Redux",
      "JavaScript",
      "Frontend Development",
    ],
    image: "./images/blog/state-management.jpg",
    featured: false,
  },
  {
    id: "type-safe-api-nodejs",
    title: "Building Type-Safe APIs with Node.js, TypeScript, and GraphQL",
    summary:
      "A comprehensive guide to creating fully type-safe backends with end-to-end type safety from database to frontend using modern tools.",
    content: `
# Building Type-Safe APIs with Node.js, TypeScript, and GraphQL

Type safety has become increasingly important in modern web development, extending beyond frontend applications into the backend realm. In this guide, we'll explore how to build fully type-safe APIs with Node.js, TypeScript, and GraphQL, creating a seamless type-safe experience from database to frontend.

## Why Type Safety Matters in APIs

Type safety provides several benefits across the full stack:

1. **Fewer Runtime Errors**: Catch errors at compile time rather than in production
2. **Better Developer Experience**: Auto-completion and inline documentation
3. **Self-Documenting Code**: Types serve as living documentation
4. **Safer Refactoring**: The compiler catches breaking changes
5. **Improved Collaboration**: Clear interfaces between different parts of the application

## The Type-Safe Stack

We'll build our API using the following technologies:

- **Node.js**: Runtime environment
- **TypeScript**: Static typing for JavaScript
- **GraphQL**: Type-safe query language
- **Prisma**: Type-safe ORM
- **Apollo Server**: GraphQL server
- **Zod**: Runtime validation
- **GraphQL Codegen**: Generate TypeScript from GraphQL schemas

Let's explore how these pieces fit together to create a fully type-safe backend.

## Setting Up the Project

First, let's initialize our project:

\`\`\`bash
mkdir type-safe-api
cd type-safe-api
npm init -y
npm install typescript ts-node @types/node --save-dev
npx tsc --init
\`\`\`

### Installing Core Dependencies

\`\`\`bash
npm install @prisma/client graphql apollo-server-express express
npm install prisma graphql-codegen-cli --save-dev
\`\`\`

## Database Layer with Prisma

Prisma provides type-safe database access with auto-generated TypeScript types.

### Defining the Schema

Create a new file \`prisma/schema.prisma\`:

\`\`\`prisma
datasource db {
  provider = "postgresql"
  url      = env("DATABASE_URL")
}

generator client {
  provider = "prisma-client-js"
}

model User {
  id        String   @id @default(uuid())
  email     String   @unique
  name      String?
  posts     Post[]
  createdAt DateTime @default(now())
  updatedAt DateTime @updatedAt
}

model Post {
  id        String   @id @default(uuid())
  title     String
  content   String?
  published Boolean  @default(false)
  author    User     @relation(fields: [authorId], references: [id])
  authorId  String
  createdAt DateTime @default(now())
  updatedAt DateTime @updatedAt
}
\`\`\`

### Generating Types and Migrating

\`\`\`bash
npx prisma migrate dev --name init
\`\`\`

This command creates the database tables and generates TypeScript types for the Prisma client.

## GraphQL Schema Definition

Create a new file \`src/schema.ts\`:

\`\`\`typescript
import { gql } from 'apollo-server-express';

export const typeDefs = gql\`
  type User {
    id: ID!
    email: String!
    name: String
    posts: [Post!]!
    createdAt: String!
    updatedAt: String!
  }

  type Post {
    id: ID!
    title: String!
    content: String
    published: Boolean!
    author: User!
    createdAt: String!
    updatedAt: String!
  }

  input CreateUserInput {
    email: String!
    name: String
  }

  input CreatePostInput {
    title: String!
    content: String
    published: Boolean
    authorId: ID!
  }

  type Query {
    users: [User!]!
    user(id: ID!): User
    posts: [Post!]!
    post(id: ID!): Post
  }

  type Mutation {
    createUser(input: CreateUserInput!): User!
    createPost(input: CreatePostInput!): Post!
    publishPost(id: ID!): Post!
  }
\`;
\`\`\`

## Type-Safe Resolvers with Prisma

Create a file \`src/resolvers.ts\`:

\`\`\`typescript
import { PrismaClient } from '@prisma/client';
import { GraphQLResolveInfo } from 'graphql';

const prisma = new PrismaClient();

// Define resolver types with TypeScript
export const resolvers = {
  Query: {
    users: async () => {
      return prisma.user.findMany({
        include: { posts: true },
      });
    },
    user: async (_: any, args: { id: string }) => {
      return prisma.user.findUnique({
        where: { id: args.id },
        include: { posts: true },
      });
    },
    posts: async () => {
      return prisma.post.findMany({
        include: { author: true },
      });
    },
    post: async (_: any, args: { id: string }) => {
      return prisma.post.findUnique({
        where: { id: args.id },
        include: { author: true },
      });
    },
  },
  Mutation: {
    createUser: async (_: any, args: { input: { email: string; name?: string } }) => {
      return prisma.user.create({
        data: args.input,
        include: { posts: true },
      });
    },
    createPost: async (_: any, args: { input: { title: string; content?: string; published?: boolean; authorId: string } }) => {
      return prisma.post.create({
        data: args.input,
        include: { author: true },
      });
    },
    publishPost: async (_: any, args: { id: string }) => {
      return prisma.post.update({
        where: { id: args.id },
        data: { published: true },
        include: { author: true },
      });
    },
  },
};
\`\`\`

## Adding Runtime Validation with Zod

While TypeScript provides compile-time type checking, we also need runtime validation:

\`\`\`bash
npm install zod
\`\`\`

Create a file \`src/validation.ts\`:

\`\`\`typescript
import { z } from 'zod';

export const CreateUserSchema = z.object({
  email: z.string().email(),
  name: z.string().optional(),
});

export const CreatePostSchema = z.object({
  title: z.string().min(1),
  content: z.string().optional(),
  published: z.boolean().optional(),
  authorId: z.string().uuid(),
});

export type CreateUserInput = z.infer<typeof CreateUserSchema>;
export type CreatePostInput = z.infer<typeof CreatePostSchema>;
\`\`\`

Update the resolvers to use validation:

\`\`\`typescript
import { CreateUserSchema, CreatePostSchema } from './validation';

// In Mutation resolvers:
createUser: async (_: any, args: { input: any }) => {
  const validatedInput = CreateUserSchema.parse(args.input);
  return prisma.user.create({
    data: validatedInput,
    include: { posts: true },
  });
},
\`\`\`

## Generating TypeScript Types from GraphQL Schema

Set up GraphQL Code Generator to create types from your GraphQL schema:

Create \`codegen.yml\`:

\`\`\`yaml
overwrite: true
schema: "src/schema.ts"
generates:
  src/generated/graphql.ts:
    plugins:
      - "typescript"
      - "typescript-resolvers"
    config:
      contextType: "../context#Context"
      mappers:
        User: "@prisma/client#User"
        Post: "@prisma/client#Post"
\`\`\`

Add a script to your package.json:

\`\`\`json
"scripts": {
  "generate": "graphql-codegen"
}
\`\`\`

Run the generator:

\`\`\`bash
npm run generate
\`\`\`

## Creating the Express Server with Apollo

Create a file \`src/server.ts\`:

\`\`\`typescript
import express from 'express';
import { ApolloServer } from 'apollo-server-express';
import { PrismaClient } from '@prisma/client';
import { typeDefs } from './schema';
import { resolvers } from './resolvers';

async function startServer() {
  const app = express();
  const prisma = new PrismaClient();

  const server = new ApolloServer({
    typeDefs,
    resolvers,
    context: { prisma }
  });

  await server.start();
  server.applyMiddleware({ app });

  const PORT = process.env.PORT || 4000;
  app.listen(PORT, () => {
    console.log(\`Server running at http://localhost:\${PORT}\${server.graphqlPath}\`);
  });
}

startServer().catch(error => console.error('Error starting server:', error));
\`\`\`

## Full Type Safety in Action

With our setup complete, we now have:

1. **Database Type Safety**: Prisma generates TypeScript types for our database schema
2. **API Type Safety**: GraphQL schema defines our API types, and GraphQL Codegen creates TypeScript interfaces
3. **Runtime Validation**: Zod ensures inputs match our expectations at runtime
4. **End-to-End Type Safety**: When used with a typed GraphQL client (like Apollo Client), types flow from database to frontend

## Extending Type Safety to the Frontend

To complete the type-safe pipeline, in your frontend application:

\`\`\`bash
npm install @apollo/client graphql
\`\`\`

Use GraphQL Code Generator on the frontend too:

\`\`\`yaml
# frontend/codegen.yml
overwrite: true
schema: "http://localhost:4000/graphql"
documents: "src/**/*.graphql"
generates:
  src/generated/graphql.tsx:
    plugins:
      - "typescript"
      - "typescript-operations"
      - "typescript-react-apollo"
\`\`\`

Create a query file \`src/queries.graphql\`:

\`\`\`graphql
query GetUsers {
  users {
    id
    name
    email
    posts {
      id
      title
    }
  }
}

mutation CreateUser($input: CreateUserInput!) {
  createUser(input: $input) {
    id
    name
    email
  }
}
\`\`\`

After running code generation, you can use typed queries in your React components:

\`\`\`tsx
import { useGetUsersQuery, useCreateUserMutation } from './generated/graphql';

function UserList() {
  const { data, loading } = useGetUsersQuery();
  
  if (loading) return <p>Loading...</p>;
  
  return (
    <ul>
      {data?.users.map(user => (
        <li key={user.id}>{user.name} ({user.email})</li>
      ))}
    </ul>
  );
}
\`\`\`

## Best Practices for Type-Safe APIs

1. **Single Source of Truth**: Use GraphQL schema as the central definition of your API types
2. **Consistent Naming**: Keep type names consistent across layers
3. **Validate at Boundaries**: Use runtime validation for all external inputs
4. **Automated Type Generation**: Regenerate types automatically in your build process
5. **Error Handling**: Add proper error types and handling throughout the stack
6. **Type Guards**: Use TypeScript type guards for runtime type narrowing
7. **Strict Mode**: Enable strict mode in TypeScript configuration

## Conclusion

Building type-safe APIs with Node.js, TypeScript, and GraphQL creates a robust development experience that catches errors early and improves collaboration. By leveraging tools like Prisma and GraphQL Code Generator, we eliminate the error-prone task of manually keeping types in sync across different layers of the application.

The result is a more reliable, maintainable, and developer-friendly API that provides guarantees about the data flowing through your system. While the initial setup requires some investment, the long-term benefits in reduced bugs and improved developer productivity make it well worth the effort.
`,
    author: "Basit Ali",
    date: "2025-02-20",
    readTime: 15,
    tags: ["Node.js", "TypeScript", "GraphQL", "API", "Backend Development"],
    image: "./images/blog/typescript-api.png",
    featured: false,
  },
  {
    id: "css-in-js-vs-utility-first",
    title: "CSS-in-JS vs. Utility-First CSS: The State of Styling in React",
    summary:
      "An in-depth comparison of the two dominant styling approaches in the React ecosystem in 2025, examining their evolution, strengths, challenges, and potential convergence.",
    content: `
  # CSS-in-JS vs. Utility-First CSS: The State of Styling in React
  
  As React continues to dominate the frontend landscape in 2025, the debate around the most effective styling approach remains as vibrant as ever. Two methodologies have emerged as frontrunners in the React ecosystem: CSS-in-JS and Utility-First CSS. In this post, we'll explore the current state of these styling paradigms, examining their strengths, weaknesses, and how the landscape has evolved.
  
  ## CSS-in-JS: The Programmatic Approach
  
  CSS-in-JS libraries like Styled Components, Emotion, and the newer Vanilla Extract have revolutionized how developers think about styling in component-based architectures.
  
  ### The Current Landscape
  
  In 2025, CSS-in-JS has matured significantly with several key developments:
  
  1. **Zero-runtime solutions are gaining traction**: Libraries like Vanilla Extract and Linaria have addressed one of the biggest criticisms of CSS-in-JS - runtime performance cost - by shifting style generation to build time.
  
  2. **TypeScript integration has become seamless**: Type safety for styles is now a standard feature, allowing developers to catch styling errors at compile time.
  
  3. **Server Components compatibility**: Newer CSS-in-JS libraries have adapted to work with React Server Components, addressing initial compatibility concerns.
  
  ### Strengths
  
  - **Component-centric**: Styles live with components, enhancing the component model that makes React powerful
  - **Dynamic styling**: Easily adapt styles based on props and state
  - **Scoped by default**: No more worrying about global namespace collisions
  - **JavaScript ecosystem**: Leverage JavaScript's full power for style logic
  
  ### Challenges
  
  - **Bundle size concerns**: Some solutions still add runtime overhead
  - **Learning curve**: Requires understanding both CSS and JavaScript paradigms
  - **Build complexity**: Can complicate the build process, especially for zero-runtime solutions
  
  ## Utility-First CSS: The Atomic Approach
  
  Tailwind CSS has become synonymous with the utility-first approach, with its adoption continuing to grow within the React community.
  
  ### The Current Landscape
  
  The utility-first ecosystem has evolved in several important ways:
  
  1. **JIT compilation**: Just-in-time compilation has revolutionized how Tailwind works, dramatically reducing build times and bundle sizes
  2. **Component libraries**: Pre-built component libraries like Tailwind UI and shadcn/ui have accelerated development with utility-first approaches
  3. **Integration with frameworks**: Automatic class sorting, linting, and framework-specific tools have improved the developer experience
  
  ### Strengths
  
  - **No context switching**: Write styles directly in your JSX without switching files
  - **Consistency**: Predefined design tokens ensure visual consistency
  - **Performance**: Minimal CSS output with high reusability
  - **Fast iteration**: Rapid prototyping and development cycles
  
  ### Challenges
  
  - **HTML verbosity**: Components can become cluttered with long class strings
  - **Learning curve**: New developers need to learn the utility naming system
  - **Customization complexity**: Complex customizations may still require custom CSS
  
  ## The Convergence: Best of Both Worlds?
  
  In 2025, we're seeing a convergence of these two approaches:
  
  1. **CSS Variables + Utility**: Libraries like CSS Modules combined with utility approaches
  2. **Style Systems**: Tools like Panda CSS bringing type-safety to utility CSS
  3. **Atomic CSS-in-JS**: Libraries combining the atomic CSS approach with component-based styling
  
  ## Making Your Choice: Decision Factors
  
  When deciding between CSS-in-JS and utility-first approaches, consider:
  
  1. **Team expertise**: Which approach aligns with your team's existing knowledge?
  2. **Project scale**: Larger projects may benefit from the stricter organization of CSS-in-JS
  3. **Performance requirements**: Consider runtime overhead for dynamic styling needs
  4. **Integration needs**: Consider your design system and component library requirements
  5. **Build process**: Evaluate how each approach impacts your build configuration
  
  ## Conclusion
  
  The "right" approach to styling in React depends heavily on your project needs, team composition, and performance requirements. Rather than viewing CSS-in-JS and utility-first as opposing methodologies, many teams are finding success with hybrid approaches that leverage the strengths of both.
  
  As React continues to evolve, we can expect styling solutions to follow suit, potentially bringing us closer to the ideal: styling that is both developer-friendly and highly performant.
  
  Whether you choose CSS-in-JS, utility-first CSS, or a hybrid approach, the most important factor remains consistent: establishing and following clear patterns that enable your team to build maintainable, scalable UI components.
    `,
    author: "Emma Chen",
    date: "2025-03-10",
    readTime: 12,
    tags: ["React", "CSS", "Frontend Development", "Styling", "Tailwind CSS"],
    image: "./images/blog/react-styling.jpeg",
    featured: true,
  },
  {
    id: "microservices-nodejs",
    title:
      "Microservices Architecture with Node.js: Patterns and Best Practices",
    summary:
      "Explore common patterns, best practices, and implementation strategies for building scalable microservices architectures with Node.js and modern tools.",
    content: `
# Microservices Architecture with Node.js: Patterns and Best Practices

Microservices architecture continues to be a dominant approach for building scalable, maintainable applications. Node.js, with its lightweight runtime and event-driven architecture, is particularly well-suited for microservices. In this post, we'll explore patterns and best practices for implementing microservices with Node.js in 2025.

## Why Microservices with Node.js?

Node.js offers several advantages for microservices implementation:

1. **Low resource footprint**: Node.js services start quickly and consume minimal resources
2. **Non-blocking I/O**: Efficiently handles concurrent requests
3. **Rich ecosystem**: Extensive libraries for service communication, monitoring, and deployment
4. **Developer productivity**: JavaScript/TypeScript ecosystem enables rapid development
5. **Containerization compatibility**: Works well in Docker and Kubernetes environments

## Key Microservices Patterns in Node.js

### 1. API Gateway Pattern

The API Gateway serves as a single entry point for clients, routing requests to appropriate services.

#### Implementation with Node.js

\`\`\`javascript
// Using Express.js as an API Gateway
const express = require('express');
const { createProxyMiddleware } = require('http-proxy-middleware');
const app = express();

// Service discovery (simplified example)
const services = {
  users: 'http://user-service:3001',
  orders: 'http://order-service:3002',
  products: 'http://product-service:3003'
};

// Route to appropriate microservices
app.use('/api/users', createProxyMiddleware({ 
  target: services.users,
  pathRewrite: {'^/api/users': '/'},
}));

app.use('/api/orders', createProxyMiddleware({ 
  target: services.orders,
  pathRewrite: {'^/api/orders': '/'},
}));

app.use('/api/products', createProxyMiddleware({ 
  target: services.products,
  pathRewrite: {'^/api/products': '/'},
}));

// Handle authentication, rate limiting, etc.
app.use((req, res, next) => {
  // Authentication logic
  next();
});

app.listen(3000, () => {
  console.log('API Gateway running on port 3000');
});
\`\`\`

More robust implementations would use dedicated API Gateway solutions like Kong, Tyk, or AWS API Gateway.

### 2. Service Registry and Discovery

For services to communicate, they need to locate each other dynamically.

#### Implementation Options

1. **Consul with Node.js**:

\`\`\`javascript
const Consul = require('consul');
const express = require('express');

const app = express();
const consul = new Consul();
const serviceName = 'order-service';
const serviceId = '\${serviceName}-\${process.env.POD_NAME || Math.random()}';

// Register service
consul.agent.service.register({
  name: serviceName,
  id: serviceId,
  address: process.env.POD_IP || 'localhost',
  port: 3000,
  check: {
    http: 'http://localhost:3000/health',
    interval: '10s'
  }
}, (err) => {
  if (err) throw err;
  console.log('Service registered with Consul');
});

// Health check endpoint
app.get('/health', (req, res) => {
  res.status(200).send('OK');
});

// Deregister on shutdown
process.on('SIGINT', () => {
  consul.agent.service.deregister(serviceId, () => {
    process.exit();
  });
});

app.listen(3000);
\`\`\`

2. **Kubernetes with Node.js**:

When running in Kubernetes, you can leverage Kubernetes' built-in service discovery:

\`\`\`javascript
const k8s = require('@kubernetes/client-node');
const kc = new k8s.KubeConfig();
kc.loadFromDefault();

const api = kc.makeApiClient(k8s.CoreV1Api);
api.listNamespacedService('default').then((res) => {
  const services = res.body.items.map(service => ({
    name: service.metadata.name,
    clusterIP: service.spec.clusterIP,
    ports: service.spec.ports
  }));
  console.log('Available services:', services);
});
\`\`\`

### 3. Circuit Breaker Pattern

Circuit breakers prevent cascading failures when a service is unavailable.

#### Implementation with Opossum:

\`\`\`javascript
const CircuitBreaker = require('opossum');
const axios = require('axios');

// Configure the circuit breaker
const breaker = new CircuitBreaker(async function makeRequest() {
  return await axios.get('http://user-service:3001/users');
}, {
  timeout: 3000, // If our function takes longer than 3 seconds, trigger a failure
  errorThresholdPercentage: 50, // When 50% of requests fail, trip the circuit
  resetTimeout: 10000 // After 10 seconds, try again
});

// Listen for events
breaker.on('open', () => console.log('Circuit breaker opened'));
breaker.on('close', () => console.log('Circuit breaker closed'));
breaker.on('halfOpen', () => console.log('Circuit breaker half-open'));

// Usage in an Express route
app.get('/users', async (req, res) => {
  try {
    const result = await breaker.fire();
    res.json(result.data);
  } catch (error) {
    // Handle the error or use fallback
    res.status(503).json({ error: 'Service unavailable' });
  }
});
\`\`\`

### 4. Event-Driven Communication

Event-driven architectures decouple services and improve resilience.

#### Implementation with RabbitMQ:

\`\`\`javascript
const amqp = require('amqplib');

async function setupMessaging() {
  // Publisher
  const publishConnection = await amqp.connect('amqp://rabbitmq:5672');
  const publishChannel = await publishConnection.createChannel();
  
  const exchange = 'order_events';
  await publishChannel.assertExchange(exchange, 'topic', { durable: true });
  
  // Publish order created event
  function publishOrderCreated(order) {
    publishChannel.publish(
      exchange,
      'order.created',
      Buffer.from(JSON.stringify(order)),
      { persistent: true }
    );
  }

  // Consumer (in another service)
  const consumeConnection = await amqp.connect('amqp://rabbitmq:5672');
  const consumeChannel = await consumeConnection.createChannel();
  
  await consumeChannel.assertExchange(exchange, 'topic', { durable: true });
  const q = await consumeChannel.assertQueue('inventory_service_queue', { durable: true });
  
  await consumeChannel.bindQueue(q.queue, exchange, 'order.created');
  
  consumeChannel.consume(q.queue, (msg) => {
    if (msg) {
      const order = JSON.parse(msg.content.toString());
      // Process order
      console.log('Processing order:', order.id);
      // Acknowledge message
      consumeChannel.ack(msg);
    }
  });
  
  return { publishOrderCreated };
}

// Usage
setupMessaging().then(({ publishOrderCreated }) => {
  // When an order is created
  publishOrderCreated({ id: '12345', items: [...], customer: '...' });
}).catch(console.error);
\`\`\`

## Deployment and Orchestration

### Container Orchestration with Kubernetes

A typical Node.js microservice Kubernetes deployment:

\`\`\`yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: order-service
spec:
  replicas: 3
  selector:
    matchLabels:
      app: order-service
  template:
    metadata:
      labels:
        app: order-service
    spec:
      containers:
      - name: order-service
        image: my-registry/order-service:1.0.0
        ports:
        - containerPort: 3000
        resources:
          limits:
            cpu: "0.5"
            memory: "512Mi"
          requests:
            cpu: "0.2"
            memory: "256Mi"
        livenessProbe:
          httpGet:
            path: /health
            port: 3000
          initialDelaySeconds: 30
          periodSeconds: 10
        readinessProbe:
          httpGet:
            path: /ready
            port: 3000
          initialDelaySeconds: 5
          periodSeconds: 5
        env:
        - name: NODE_ENV
          value: "production"
        - name: DATABASE_URL
          valueFrom:
            secretKeyRef:
              name: order-service-secrets
              key: database-url
---
apiVersion: v1
kind: Service
metadata:
  name: order-service
spec:
  selector:
    app: order-service
  ports:
  - port: 80
    targetPort: 3000
  type: ClusterIP
\`\`\`

## Monitoring and Observability

### Distributed Tracing with OpenTelemetry

\`\`\`javascript
const { NodeTracerProvider } = require('@opentelemetry/node');
const { registerInstrumentations } = require('@opentelemetry/instrumentation');
const { ExpressInstrumentation } = require('@opentelemetry/instrumentation-express');
const { HttpInstrumentation } = require('@opentelemetry/instrumentation-http');
const { JaegerExporter } = require('@opentelemetry/exporter-jaeger');
const { SimpleSpanProcessor } = require('@opentelemetry/tracing');

// Initialize tracer
const provider = new NodeTracerProvider();

// Configure span exporter
const exporter = new JaegerExporter({
  serviceName: 'order-service',
  endpoint: 'http://jaeger:14268/api/traces',
});

// Register span processor
provider.addSpanProcessor(new SimpleSpanProcessor(exporter));
provider.register();

// Register instrumentations
registerInstrumentations({
  instrumentations: [
    new HttpInstrumentation(),
    new ExpressInstrumentation(),
  ],
});

// Express app setup
const express = require('express');
const app = express();

app.get('/orders/:id', async (req, res) => {
  const tracer = provider.getTracer('order-service-tracer');
  const span = tracer.startSpan('get-order-details');
  
  try {
    // DB query or external service call
    span.setAttributes({ 'order.id': req.params.id });
    // Fetch order logic
    res.json({ id: req.params.id, status: 'shipped' });
  } catch (error) {
    span.recordException(error);
    res.status(500).json({ error: 'Failed to retrieve order' });
  } finally {
    span.end();
  }
});

app.listen(3000);
\`\`\`

## Best Practices for Node.js Microservices

1. **Use Domain-Driven Design**: Structure services around business domains
2. **Implement Health Checks**: Enable monitoring systems to detect service health
3. **Centralize Logging**: Aggregate logs for better debugging and monitoring
4. **Apply the Twelve-Factor App Methodology**: Follow principles for cloud-native applications
5. **Implement API Versioning**: Allow services to evolve independently
6. **Use Graceful Shutdowns**: Handle termination signals properly
7. **Implement Rate Limiting**: Protect services from overload
8. **Use Containerization**: Package services as containers for consistent deployment
9. **Apply the Bulkhead Pattern**: Isolate failures to prevent system-wide outages
10. **Implement Retry Logic**: Handle transient failures gracefully

## Conclusion

Microservices with Node.js provide a powerful combination for building scalable, maintainable systems. By implementing the patterns and practices outlined in this article, you can create resilient services that can evolve independently while working together as a cohesive system.

Remember that microservices add complexity, so start with clear boundaries, effective communication patterns, and robust monitoring. As your architecture grows, continuously refine your approach based on operational feedback and evolving business needs.
`,
    author: "Priya Sharma",
    date: "2025-03-01",
    readTime: 14,
    tags: [
      "Node.js",
      "Microservices",
      "Backend Development",
      "Architecture",
      "DevOps",
    ],
    image: "./images/blog/microservices-nodejs.webp",
    featured: true,
  },
  {
    id: "realtime-nodejs-applications",
    title: "Real-time Applications with Node.js: WebSockets, SSE, and Beyond",
    summary:
      "Dive into the world of real-time web applications using Node.js with a comprehensive comparison of different real-time communication technologies and implementation strategies.",
    content: `
  # Real-time Applications with Node.js: WebSockets, SSE, and Beyond
  
  Real-time functionality has become essential for modern web applications, from collaborative tools and live dashboards to instant messaging and multiplayer games. Node.js, with its event-driven architecture, is perfectly suited for building real-time applications. In this comprehensive guide, we'll explore different approaches to implementing real-time features with Node.js.
  
  ## Understanding Real-time Communication Options
  
  Before diving into implementation, let's understand the different technologies available for real-time communication:
  
  ### 1. WebSockets
  
  WebSockets provide a persistent, bi-directional communication channel between client and server. They're ideal for applications requiring low latency and frequent two-way communication.
  
  ### 2. Server-Sent Events (SSE)
  
  SSE establishes a one-way connection from server to client, allowing the server to push updates to clients. They're simpler than WebSockets and work well for applications where data primarily flows from server to client.
  
  ### 3. HTTP Long Polling
  
  An older technique where the client makes a request and the server holds the response until new data is available or a timeout occurs. The client immediately sends a new request after receiving a response.
  
  ### 4. WebRTC
  
  Web Real-Time Communication enables direct peer-to-peer communication between browsers, including data, audio, and video.
  
  ## Real-time with WebSockets in Node.js
  
  WebSockets are the most popular choice for real-time applications due to their flexibility and performance.
  
  ### Implementation with Socket.io
  
  Socket.io is a powerful library that abstracts WebSockets and provides fallbacks for older browsers:
  
  \`\`\`javascript
  // Server (app.js)
  const express = require('express');
  const { createServer } = require('http');
  const { Server } = require('socket.io');
  
  const app = express();
  const httpServer = createServer(app);
  const io = new Server(httpServer, {
    cors: {
      origin: "http://localhost:3000",
      methods: ["GET", "POST"]
    }
  });
  
  // Serve static files
  app.use(express.static('public'));
  
  // Socket.io connection handling
  io.on('connection', (socket) => {
    console.log('New client connected', socket.id);
    
    // Join a room (e.g., for a specific chat channel)
    socket.on('join-room', (roomId) => {
      socket.join(roomId);
      console.log(\`Socket \${socket.id} joined room \${roomId}\`);
    });
    
    // Handle incoming messages
    socket.on('send-message', (data) => {
      // Broadcast to everyone in the room except sender
      socket.to(data.roomId).emit('receive-message', {
        content: data.content,
        senderId: socket.id,
        timestamp: new Date()
      });
    });
    
    // Handle typing indicators
    socket.on('typing', (data) => {
      socket.to(data.roomId).emit('user-typing', {
        userId: socket.id
      });
    });
    
    // Handle disconnection
    socket.on('disconnect', () => {
      console.log('Client disconnected', socket.id);
    });
  });
  
  httpServer.listen(3000, () => {
    console.log('Server listening on port 3000');
  });
  \`\`\`
  
  ### Client-side Implementation
  
  \`\`\`javascript
  // Client (public/app.js)
  const socket = io('http://localhost:3000');
  const messageForm = document.getElementById('message-form');
  const messageInput = document.getElementById('message-input');
  const messagesList = document.getElementById('messages');
  const roomSelector = document.getElementById('room-selector');
  let currentRoom = 'general';
  
  // Join default room
  socket.emit('join-room', currentRoom);
  
  // Handle room changes
  roomSelector.addEventListener('change', () => {
    // Leave current room
    socket.emit('leave-room', currentRoom);
    
    // Join new room
    currentRoom = roomSelector.value;
    socket.emit('join-room', currentRoom);
    
    // Clear messages
    messagesList.innerHTML = '';
  });
  
  // Handle form submission
  messageForm.addEventListener('submit', (e) => {
    e.preventDefault();
    const content = messageInput.value.trim();
    
    if (content) {
      // Send message to server
      socket.emit('send-message', {
        content,
        roomId: currentRoom
      });
      
      // Add message to UI
      addMessage({
        content,
        senderId: 'me',
        timestamp: new Date()
      });
      
      // Clear input
      messageInput.value = '';
    }
  });
  
  // Handle typing indicator
  let typingTimeout;
  messageInput.addEventListener('input', () => {
    clearTimeout(typingTimeout);
    
    socket.emit('typing', {
      roomId: currentRoom
    });
    
    typingTimeout = setTimeout(() => {
      socket.emit('stop-typing', {
        roomId: currentRoom
      });
    }, 1000);
  });
  
  // Handle incoming messages
  socket.on('receive-message', (message) => {
    addMessage(message);
  });
  
  // Handle typing indicators
  socket.on('user-typing', (data) => {
    showTypingIndicator(data.userId);
  });
  
  // Handle connection status
  socket.on('connect', () => {
    console.log('Connected to server');
  });
  
  socket.on('disconnect', () => {
    console.log('Disconnected from server');
  });
  
  // Helper to add message to UI
  function addMessage(message) {
    const li = document.createElement('li');
    li.className = message.senderId === 'me' ? 'sent' : 'received';
    li.innerHTML = \`
      <span class="message-content">\${message.content}</span>
      <span class="message-time">\${new Date(
        message.timestamp
      ).toLocaleTimeString()}</span>
    \`;
    messagesList.appendChild(li);
    messagesList.scrollTop = messagesList.scrollHeight;
  }
  
  // Helper to show typing indicator
  function showTypingIndicator(userId) {
    const typingIndicator = document.getElementById('typing-indicator');
    typingIndicator.textContent = \`Someone is typing...\`;
    typingIndicator.style.display = 'block';
    
    setTimeout(() => {
      typingIndicator.style.display = 'none';
    }, 1000);
  }
  \`\`\`
  
  ### Scaling WebSockets with Redis Adapter
  
  When running multiple Node.js instances, you'll need a way to coordinate messages between servers:
  
  \`\`\`javascript
  const express = require('express');
  const { createServer } = require('http');
  const { Server } = require('socket.io');
  const { createAdapter } = require('@socket.io/redis-adapter');
  const { createClient } = require('redis');
  
  const app = express();
  const httpServer = createServer(app);
  const io = new Server(httpServer);
  
  // Create Redis clients
  const pubClient = createClient({ url: 'redis://redis:6379' });
  const subClient = pubClient.duplicate();
  
  // Initialize Redis adapter
  Promise.all([pubClient.connect(), subClient.connect()]).then(() => {
    io.adapter(createAdapter(pubClient, subClient));
    console.log('Socket.io Redis adapter initialized');
  });
  
  // Socket.io connection handling
  io.on('connection', (socket) => {
    // ... same handling as before
  });
  
  httpServer.listen(3000);
  \`\`\`
  
  ## Real-time with Server-Sent Events (SSE)
  
  SSE is a simpler alternative to WebSockets for cases where you only need one-way communication from server to client.
  
  ### Server Implementation
  
  \`\`\`javascript
  const express = require('express');
  const app = express();
  
  app.use(express.static('public'));
  
  // SSE endpoint
  app.get('/events', (req, res) => {
    // Set SSE headers
    res.setHeader('Content-Type', 'text/event-stream');
    res.setHeader('Cache-Control', 'no-cache');
    res.setHeader('Connection', 'keep-alive');
    
    // Send initial connection confirmation
    res.write('event: connected\\n');
    res.write(\`data: \${JSON.stringify({
      message: "Connected to event stream",
    })}\\n\\n\`);
    
    // Function to send updates
    const sendUpdate = (data) => {
      res.write(\`event: update\\n\`);
      res.write(\`data: \${JSON.stringify(data)}\\n\\n\`);
    };
    
    // Add client to broadcaster
    const clientId = Date.now();
    clients.set(clientId, sendUpdate);
    
    // Remove client on disconnect
    req.on('close', () => {
      clients.delete(clientId);
      console.log(\`Client \${clientId} disconnected\`);
    });
  });
  
  // Store connected clients
  const clients = new Map();
  
  // Simulate updates (e.g., stock prices)
  setInterval(() => {
    const data = {
      time: new Date().toISOString(),
      stocks: [
        { symbol: 'AAPL', price: 150 + Math.random() * 10 },
        { symbol: 'GOOGL', price: 2500 + Math.random() * 50 },
        { symbol: 'MSFT', price: 300 + Math.random() * 15 }
      ]
    };
    
    // Broadcast to all connected clients
    clients.forEach(sendUpdate => {
      sendUpdate(data);
    });
  }, 2000);
  
  app.listen(3000, () => {
    console.log('SSE server listening on port 3000');
  });
  \`\`\`
  
  ### Client Implementation
  
  \`\`\`javascript
  // Client (public/sse-client.js)
  document.addEventListener('DOMContentLoaded', () => {
    const stockList = document.getElementById('stock-list');
    
    // Create EventSource
    const eventSource = new EventSource('/events');
    
    // Handle connection established
    eventSource.addEventListener('connected', (event) => {
      console.log('Connected to SSE:', JSON.parse(event.data));
    });
    
    // Handle updates
    eventSource.addEventListener('update', (event) => {
      const data = JSON.parse(event.data);
      updateStockDisplay(data);
    });
    
    // Handle errors
    eventSource.addEventListener('error', (error) => {
      console.error('SSE Error:', error);
      eventSource.close();
      
      // Attempt to reconnect after delay
      setTimeout(() => {
        console.log('Reconnecting...');
        window.location.reload();
      }, 5000);
    });
    
    // Update UI with stock data
    function updateStockDisplay(data) {
      stockList.innerHTML = '';
      data.stocks.forEach(stock => {
        const li = document.createElement('li');
        li.className = 'stock-item';
        li.innerHTML = \`
          <span class="stock-symbol">\${stock.symbol}</span>
          <span class="stock-price">$\${stock.price.toFixed(2)}</span>
        \`;
        stockList.appendChild(li);
      });
      
      // Update timestamp
      document.getElementById('last-update').textContent = 
        new Date(data.time).toLocaleTimeString();
    }
  });
  \`\`\`
  
  ## Real-time with HTTP Long Polling
  
  While less common today, long polling is still useful for compatibility with older clients or simpler implementations.
  
  ### Server Implementation
  
  \`\`\`javascript
  const express = require('express');
  const app = express();
  
  app.use(express.static('public'));
  app.use(express.json());
  
  // Store pending requests
  const pendingRequests = [];
  // Store messages
  const messages = [];
  
  // Long polling endpoint
  app.get('/poll', (req, res) => {
    const lastMessageId = parseInt(req.query.lastId) || 0;
    
    // Check if there are new messages
    const newMessages = messages.filter(msg => msg.id > lastMessageId);
    
    if (newMessages.length > 0) {
      // Send new messages immediately
      res.json({ messages: newMessages });
    } else {
      // Store the request to respond later
      const requestObj = { req, res };
      pendingRequests.push(requestObj);
      
      // Set timeout to avoid hanging connections
      req.setTimeout(30000, () => {
        // Remove request from pending list
        const index = pendingRequests.indexOf(requestObj);
        if (index !== -1) {
          pendingRequests.splice(index, 1);
        }
        // Send empty response after timeout
        res.json({ messages: [] });
      });
      
      // Handle client disconnect
      req.on('close', () => {
        const index = pendingRequests.indexOf(requestObj);
        if (index !== -1) {
          pendingRequests.splice(index, 1);
        }
      });
    }
  });
  
  // Endpoint to post new messages
  app.post('/messages', (req, res) => {
    const newMessage = {
      id: messages.length + 1,
      text: req.body.text,
      timestamp: new Date()
    };
    
    messages.push(newMessage);
    
    // Respond to all pending poll requests
    pendingRequests.forEach(({ res }) => {
      res.json({ messages: [newMessage] });
    });
    
    // Clear pending requests
    pendingRequests.length = 0;
    
    res.status(201).json({ success: true, message: newMessage });
  });
  
  app.listen(3000, () => {
    console.log('Long polling server listening on port 3000');
  });
  \`\`\`
  
  ### Client Implementation
  
  \`\`\`javascript
  // Client (public/long-polling.js)
  document.addEventListener('DOMContentLoaded', () => {
    const messagesList = document.getElementById('messages');
    const messageForm = document.getElementById('message-form');
    const messageInput = document.getElementById('message-input');
    
    let lastMessageId = 0;
    
    // Start long polling
    function poll() {
      fetch(\`/poll?lastId=\${lastMessageId}\`)
        .then(response => response.json())
        .then(data => {
          // Process new messages
          if (data.messages && data.messages.length > 0) {
            data.messages.forEach(message => {
              displayMessage(message);
              lastMessageId = message.id;
            });
          }
          // Continue polling
          poll();
        })
        .catch(error => {
          console.error('Polling error:', error);
          // Retry after delay
          setTimeout(poll, 5000);
        });
    }
    
    // Send message
    messageForm.addEventListener('submit', (e) => {
      e.preventDefault();
      const text = messageInput.value.trim();
      
      if (text) {
        fetch('/messages', {
          method: 'POST',
          headers: {
            'Content-Type': 'application/json'
          },
          body: JSON.stringify({ text })
        })
          .then(response => response.json())
          .then(data => {
            // Clear input field
            messageInput.value = '';
          })
          .catch(error => {
            console.error('Error sending message:', error);
          });
      }
    });
    
    // Display message in UI
    function displayMessage(message) {
      const li = document.createElement('li');
      li.className = 'message-item';
      li.innerHTML = \`
        <div class="message-text">\${message.text}</div>
        <div class="message-time">\${new Date(
          message.timestamp
        ).toLocaleTimeString()}</div>
      \`;
      messagesList.appendChild(li);
      messagesList.scrollTop = messagesList.scrollHeight;
    }
    
    // Start polling
    poll();
  });
  \`\`\`
  
  ## WebRTC for Peer-to-Peer Communication
  
  For direct client-to-client communication, WebRTC is the go-to technology.
  
  ### Signaling Server with Node.js
  
  \`\`\`javascript
  const express = require('express');
  const { createServer } = require('http');
  const { Server } = require('socket.io');
  
  const app = express();
  const httpServer = createServer(app);
  const io = new Server(httpServer);
  
  app.use(express.static('public'));
  
  // WebRTC signaling
  io.on('connection', (socket) => {
    console.log('Client connected for WebRTC signaling:', socket.id);
    
    // Handle room joining
    socket.on('join-room', (roomId) => {
      // Leave previous rooms
      Array.from(socket.rooms)
        .filter(r => r !== socket.id)
        .forEach(r => socket.leave(r));
      
      // Join new room
      socket.join(roomId);
      
      // Notify other participants
      socket.to(roomId).emit('user-joined', socket.id);
      
      // Send list of participants to the new user
      const clients = io.sockets.adapter.rooms.get(roomId) || new Set();
      const otherClients = Array.from(clients).filter(id => id !== socket.id);
      socket.emit('existing-users', otherClients);
    });
    
    // Forward WebRTC signaling messages
    socket.on('signal', ({ userId, signal }) => {
      socket.to(userId).emit('signal', {
        userId: socket.id,
        signal
      });
    });
    
    // Handle disconnection
    socket.on('disconnect', () => {
      // Notify all rooms this user was in
      socket.rooms.forEach(room => {
        socket.to(room).emit('user-left', socket.id);
      });
    });
  });
  
  httpServer.listen(3000, () => {
    console.log('WebRTC signaling server listening on port 3000');
  });
  \`\`\`
  
  ## Comparing Real-time Technologies in Node.js
  
  | Technology | Pros | Cons | Best For |
  |------------|------|------|----------|
  | WebSockets | Full-duplex communication, low latency, widely supported | More complex setup, can be blocked by firewalls | Interactive apps, chat, gaming, collaborative editing |
  | SSE | Simple to implement, native browser support, automatic reconnection | One-way communication only (server to client) | Dashboards, notifications, news feeds, stock tickers |
  | Long Polling | Works with older browsers, simpler to implement | Higher server load, less efficient, more latency | Legacy system compatibility, simple notification systems |
  | WebRTC | Direct peer-to-peer communication, low latency, supports media | Complex setup, requires signaling server, NAT traversal issues | Video/audio calls, P2P file sharing, decentralized apps |
  
  ## Real-time Best Practices in Node.js
  
  1. **Handle reconnection gracefully**: Implement proper reconnection logic with exponential backoff to avoid overwhelming servers during outages
  
  2. **Use heartbeats**: Implement periodic ping/pong messages to detect stale connections
  
  3. **Implement proper error handling**: Provide fallback mechanisms when real-time connections fail
  
  4. **Consider message delivery guarantees**: Decide whether you need at-least-once, at-most-once, or exactly-once delivery
  
  5. **Use connection pooling**: For databases and other resources to avoid connection exhaustion
  
  6. **Implement rate limiting**: Protect against message flooding from malicious clients
  
  7. **Design for horizontal scaling**: Use Redis or other pub/sub mechanisms for multi-server setups
  
  8. **Monitor connection health**: Track metrics like connection duration, message rates, and errors
  
  9. **Structure your events**: Use consistent naming and payload structures
  
  10. **Implement authorization**: Secure your real-time communication with proper authentication
  
  ## Building a Complete Real-time Dashboard Example
  
  Let's build a real-time dashboard that combines SSE for data updates and WebSockets for user interactions:
  
  ### Server Implementation
  
  \`\`\`javascript
  const express = require('express');
  const http = require('http');
  const { Server } = require('socket.io');
  const { EventEmitter } = require('events');
  
  const app = express();
  const server = http.createServer(app);
  const io = new Server(server);
  
  // Create event bus for cross-communication
  const eventBus = new EventEmitter();
  
  // Serve static files
  app.use(express.static('public'));
  app.use(express.json());
  
  // Store connected SSE clients
  const sseClients = new Map();
  
  // SSE endpoint for dashboard data
  app.get('/dashboard-updates', (req, res) => {
    const clientId = Date.now();
    
    // Set SSE headers
    res.setHeader('Content-Type', 'text/event-stream');
    res.setHeader('Cache-Control', 'no-cache');
    res.setHeader('Connection', 'keep-alive');
    
    // Send initial data
    const initialData = {
      activeUsers: getActiveUserCount(),
      systemStatus: getSystemStatus(),
      recentTransactions: getRecentTransactions()
    };
    
    res.write(\`data: \${JSON.stringify(initialData)}\\n\\n\`);
    
    // Function to send updates to this client
    const sendUpdate = (data) => {
      res.write(\`data: \${JSON.stringify(data)}\\n\\n\`);
    };
    
    // Store client callback
    sseClients.set(clientId, sendUpdate);
    
    // Remove client on disconnect
    req.on('close', () => {
      sseClients.delete(clientId);
      console.log(\`SSE client \${clientId} disconnected\`);
    });
  });
  
  // WebSocket for interactive features
  io.on('connection', (socket) => {
    console.log('Socket client connected:', socket.id);
    
    // Handle admin commands
    socket.on('system-command', (data) => {
      // Check authentication
      if (!isAuthorized(socket, 'admin')) {
        socket.emit('error', { message: 'Not authorized' });
        return;
      }
      
      console.log(\`Admin command received: \${data.command}\`);
      
      // Process command
      switch (data.command) {
        case 'restart-service':
          // Simulate service restart
          setTimeout(() => {
            const updateData = {
              systemStatus: {
                status: 'restarting',
                lastUpdated: new Date().toISOString()
              }
            };
            
            // Broadcast to all SSE clients
            broadcastSSE(updateData);
            
            // After restart completes
            setTimeout(() => {
              const completionData = {
                systemStatus: {
                  status: 'online',
                  lastUpdated: new Date().toISOString()
                }
              };
              broadcastSSE(completionData);
            }, 3000);
          }, 500);
          break;
          
        default:
          socket.emit('error', { message: 'Unknown command' });
      }
    });
    
    // Handle user actions
    socket.on('user-action', (data) => {
      console.log(\`User action: \${data.action}\`);
      
      // Process action and broadcast updates if needed
      if (data.action === 'new-transaction') {
        const transaction = {
          id: generateTransactionId(),
          amount: data.amount,
          user: data.userId,
          type: data.type,
          timestamp: new Date().toISOString()
        };
        
        // Add to recent transactions
        addTransaction(transaction);
        
        // Broadcast update
        broadcastSSE({
          recentTransactions: getRecentTransactions()
        });
      }
    });
    
    // Handle disconnect
    socket.on('disconnect', () => {
      console.log('Socket client disconnected:', socket.id);
    });
  });
  
  // Broadcast to all SSE clients
  function broadcastSSE(data) {
    sseClients.forEach(sendUpdate => {
      sendUpdate(data);
    });
  }
  
  // Simulate periodic updates
  setInterval(() => {
    const updateData = {
      activeUsers: getActiveUserCount(),
      systemMetrics: {
        cpuUsage: Math.floor(Math.random() * 100),
        memoryUsage: Math.floor(Math.random() * 100),
        requestsPerMinute: Math.floor(Math.random() * 1000)
      }
    };
    
    broadcastSSE(updateData);
  }, 5000);
  
  // Helper functions (simulated)
  function getActiveUserCount() {
    return Math.floor(Math.random() * 100) + 50;
  }
  
  function getSystemStatus() {
    return {
      status: 'online',
      lastUpdated: new Date().toISOString()
    };
  }
  
  let recentTransactions = [];
  function getRecentTransactions() {
    return recentTransactions.slice(0, 10);
  }
  
  function addTransaction(transaction) {
    recentTransactions.unshift(transaction);
    if (recentTransactions.length > 100) {
      recentTransactions = recentTransactions.slice(0, 100);
    }
  }
  
  function generateTransactionId() {
    return Math.random().toString(36).substring(2, 15);
  }
  
  function isAuthorized(socket, role) {
    // This would typically check JWT or session
    return socket.handshake.auth && socket.handshake.auth.role === role;
  }
  
  server.listen(3000, () => {
    console.log('Real-time dashboard server running on port 3000');
  });
  \`\`\`
  
  ## Conclusion: Choosing the Right Real-time Technology
  
  Selecting the appropriate real-time technology for your Node.js application depends on several factors:
  
  1. **Communication pattern**: If you need bi-directional communication, WebSockets are likely your best choice. For server-to-client updates only, SSE may be simpler.
  
  2. **Client support**: Consider browser compatibility if you need to support older browsers.
  
  3. **Scalability requirements**: WebSockets maintain persistent connections, which may require more server resources as your user base grows.
  
  4. **Message frequency**: High-frequency updates benefit from WebSockets' lower overhead, while occasional updates might be fine with SSE or even long polling.
  
  5. **Development complexity**: SSE is generally simpler to implement than WebSockets, while WebRTC has the steepest learning curve.
  
  Node.js excels at real-time applications due to its event-driven, non-blocking architecture. By choosing the right communication technology and following best practices, you can build responsive, scalable applications that provide users with dynamic, interactive experiences.
  
  Remember that it's also possible to combine these technologies - for example, using SSE for data updates and WebSockets for user interactions - to leverage the strengths of each approach for different aspects of your application.
    `,
    author: "Marco Rodriguez",
    date: "2025-02-20",
    readTime: 16,
    tags: [
      "Node.js",
      "WebSockets",
      "Real-time",
      "Socket.io",
      "SSE",
      "Backend Development",
    ],
    image: "./images/blog/realtime-nodejs.webp",
    featured: true,
  },
  {
    id: "auth-modern-nodejs",
    title: "Authentication and Authorization in Modern Node.js Applications",
    summary:
      "A comprehensive guide to implementing secure authentication and authorization systems in Node.js applications using modern approaches and best practices.",
    content: `
  # Authentication and Authorization in Modern Node.js Applications
  
  User authentication and authorization are critical components of any production application. As security threats continue to evolve, implementing robust auth systems has become increasingly complex. This guide explores modern approaches to authentication and authorization in Node.js applications in 2025, balancing security with developer experience.
  
  ## The Modern Auth Landscape
  
  Authentication and authorization have evolved significantly in recent years:
  
  1. **Token-based auth dominates**: JWT (JSON Web Tokens) has become the standard for stateless authentication
  2. **OAuth 2.0 and OIDC**: Standards for delegated authorization and authentication
  3. **Passwordless authentication**: Email magic links and WebAuthn/FIDO2 for better security
  4. **Multi-factor authentication**: Now considered essential for sensitive applications
  5. **Microservice-friendly approaches**: Distributed auth patterns for modern architectures
  
  Let's explore how to implement these approaches in Node.js applications.
  
  ## JWT-Based Authentication
  
  JWT provides a compact, self-contained way to represent claims securely between parties.
  
  ### Implementation with Express
  
  \`\`\`javascript
  const express = require('express');
  const jwt = require('jsonwebtoken');
  const bcrypt = require('bcrypt');
  const { body, validationResult } = require('express-validator');
  
  const app = express();
  app.use(express.json());
  
  // Secret key for JWT signing (in production, store securely)
  const JWT_SECRET = process.env.JWT_SECRET || 'your-secret-key';
  const JWT_EXPIRATION = '1h';
  
  // Mock user database (use a real database in production)
  const users = [];
  
  // Register new user
  app.post('/register', [
    body('email').isEmail().normalizeEmail(),
    body('password').isLength({ min: 8 }),
    body('name').trim().notEmpty()
  ], async (req, res) => {
    // Validate input
    const errors = validationResult(req);
    if (!errors.isEmpty()) {
      return res.status(400).json({ errors: errors.array() });
    }
    
    const { email, password, name } = req.body;
    
    // Check if user already exists
    if (users.find(u => u.email === email)) {
      return res.status(409).json({ message: 'User already exists' });
    }
    
    try {
      // Hash password
      const hashedPassword = await bcrypt.hash(password, 10);
      
      // Create new user
      const newUser = {
        id: Date.now().toString(),
        email,
        password: hashedPassword,
        name,
        roles: ['user'],
        createdAt: new Date()
      };
      
      users.push(newUser);
      
      res.status(201).json({
        message: 'User registered successfully',
        userId: newUser.id
      });
    } catch (error) {
      console.error('Registration error:', error);
      res.status(500).json({ message: 'Error registering user' });
    }
  });
  
  // Login
  app.post('/login', [
    body('email').isEmail().normalizeEmail(),
    body('password').notEmpty()
  ], async (req, res) => {
    // Validate input
    const errors = validationResult(req);
    if (!errors.isEmpty()) {
      return res.status(400).json({ errors: errors.array() });
    }
    
    const { email, password } = req.body;
    
    // Find user
    const user = users.find(u => u.email === email);
    if (!user) {
      return res.status(401).json({ message: 'Invalid credentials' });
    }
    
    try {
      // Verify password
      const passwordMatch = await bcrypt.compare(password, user.password);
      if (!passwordMatch) {
        return res.status(401).json({ message: 'Invalid credentials' });
      }
      
      // Create JWT payload (avoid including sensitive data)
      const payload = {
        sub: user.id,
        email: user.email,
        name: user.name,
        roles: user.roles
      };
      
      // Sign token
      const token = jwt.sign(payload, JWT_SECRET, {
        expiresIn: JWT_EXPIRATION
      });
      
      // Create refresh token (for production apps)
      const refreshToken = jwt.sign(
        { sub: user.id },
        JWT_SECRET,
        { expiresIn: '7d' }
      );
      
      // Return tokens
      res.json({
        message: 'Login successful',
        accessToken: token,
        refreshToken,
        expiresIn: 3600 // 1 hour in seconds
      });
    } catch (error) {
      console.error('Login error:', error);
      res.status(500).json({ message: 'Error during login' });
    }
  });
  
  // Refresh token endpoint
  app.post('/refresh-token', (req, res) => {
    const { refreshToken } = req.body;
    
    if (!refreshToken) {
      return res.status(400).json({ message: 'Refresh token is required' });
    }
    
    try {
      // Verify refresh token
      const decoded = jwt.verify(refreshToken, JWT_SECRET);
      
      // Find user
      const user = users.find(u => u.id === decoded.sub);
      if (!user) {
        return res.status(404).json({ message: 'User not found' });
      }
      
      // Create new access token
      const payload = {
        sub: user.id,
        email: user.email,
        name: user.name,
        roles: user.roles
      };
      
      const newAccessToken = jwt.sign(payload, JWT_SECRET, {
        expiresIn: JWT_EXPIRATION
      });
      
      res.json({
        accessToken: newAccessToken,
        expiresIn: 3600 // 1 hour in seconds
      });
    } catch (error) {
      console.error('Token refresh error:', error);
      res.status(401).json({ message: 'Invalid refresh token' });
    }
  });
  
  // Middleware for authentication
  function authenticateToken(req, res, next) {
    const authHeader = req.headers['authorization'];
    const token = authHeader && authHeader.split(' ')[1];
    
    if (!token) {
      return res.status(401).json({ message: 'Authentication required' });
    }
    
    jwt.verify(token, JWT_SECRET, (err, decoded) => {
      if (err) {
        return res.status(403).json({ message: 'Invalid or expired token' });
      }
      
      req.user = decoded;
      next();
    });
  }
  
  // Protected route example
  app.get('/profile', authenticateToken, (req, res) => {
    // req.user contains the decoded token payload
    res.json({
      user: {
        id: req.user.sub,
        email: req.user.email,
        name: req.user.name
      }
    });
  });
  
  // Authorization middleware
  function authorize(roles = []) {
    return (req, res, next) => {
      if (!req.user) {
        return res.status(401).json({ message: 'Authentication required' });
      }
      
      if (roles.length && !req.user.roles.some(role => roles.includes(role))) {
        return res.status(403).json({ message: 'Insufficient permissions' });
      }
      
      next();
    };
  }
  
  // Admin-only route example
  app.get('/admin/dashboard', authenticateToken, authorize(['admin']), (req, res) => {
    res.json({ message: 'Admin dashboard data', stats: { users: users.length } });
  });
  
  app.listen(3000, () => {
    console.log('Auth server listening on port 3000');
  });
  \`\`\`
  
  ## Passwordless Authentication
  
  Passwordless auth enhances security by eliminating password vulnerabilities:
  
  ### Magic Link Implementation
  
  \`\`\`javascript
  const express = require('express');
  const crypto = require('crypto');
  const nodemailer = require('nodemailer');
  const jwt = require('jsonwebtoken');
  
  const app = express();
  app.use(express.json());
  
  // Config
  const JWT_SECRET = process.env.JWT_SECRET || 'your-secret-key';
  const EMAIL_TOKEN_EXPIRATION = 10 * 60 * 1000; // 10 minutes in ms
  const LOGIN_URL = 'http://localhost:3000/verify-login';
  
  // Mock user database and token storage
  const users = [];
  const emailTokens = new Map();
  
  // Configure email transport (use a real SMTP service in production)
  const emailTransport = nodemailer.createTransport({
    host: 'smtp.example.com',
    port: 587,
    secure: false,
    auth: {
      user: process.env.EMAIL_USER,
      pass: process.env.EMAIL_PASSWORD
    }
  });
  
  // Request magic link
  app.post('/login/email', async (req, res) => {
    const { email } = req.body;
    
    if (!email || !email.includes('@')) {
      return res.status(400).json({ message: 'Valid email is required' });
    }
    
    try {
      // Find or create user
      let user = users.find(u => u.email === email);
      if (!user) {
        user = {
          id: Date.now().toString(),
          email,
          createdAt: new Date(),
          roles: ['user']
        };
        users.push(user);
      }
      
      // Generate secure random token
      const token = crypto.randomBytes(32).toString('hex');
      
      // Store token with expiration
      emailTokens.set(token, {
        userId: user.id,
        email,
        expires: Date.now() + EMAIL_TOKEN_EXPIRATION
      });
      
      // Create magic link
      const magicLink = \`\${LOGIN_URL}?token=\${token}\`;
      
      // Send email
      await emailTransport.sendMail({
        from: '"Your App" <auth@yourapp.com>',
        to: email,
        subject: 'Your login link',
        text: \`Click this link to login: \${magicLink}\`,
        html: \`<p>Click <a href="\${magicLink}">here</a> to login.</p>\`
      });
      
      res.json({ message: 'Magic link sent to email' });
    } catch (error) {
      console.error('Magic link error:', error);
      res.status(500).json({ message: 'Error sending magic link' });
    }
  });
  
  // Verify magic link token
  app.get('/verify-login', (req, res) => {
    const { token } = req.query;
    
    if (!token) {
      return res.status(400).send('Token is required');
    }
    
    // Get token data
    const tokenData = emailTokens.get(token);
    if (!tokenData) {
      return res.status(400).send('Invalid token');
    }
    
    // Check expiration
    if (Date.now() > tokenData.expires) {
      emailTokens.delete(token);
      return res.status(400).send('Token expired');
    }
    
    // Find user
    const user = users.find(u => u.id === tokenData.userId);
    if (!user) {
      return res.status(404).send('User not found');
    }
    
    // Generate JWT
    const jwtPayload = {
      sub: user.id,
      email: user.email,
      roles: user.roles
    };
    
    const accessToken = jwt.sign(jwtPayload, JWT_SECRET, { expiresIn: '1h' });
    
    // Clear magic link token
    emailTokens.delete(token);
    
    // In a real app, redirect to frontend with token
    res.send(\`
      <html>
        <body>
          <h1>Login Successful!</h1>
          <p>Your access token: \${accessToken}</p>
          <script>
            // In production, store token and redirect
            localStorage.setItem('accessToken', '\${accessToken}');
            // window.location = '/dashboard';
          </script>
        </body>
      </html>
    \`);
  });
  
  app.listen(3000, () => {
    console.log('Passwordless auth server listening on port 3000');
  });
  \`\`\`
  
  ## OAuth 2.0 and OpenID Connect
  
  For third-party authentication and single sign-on:
  
  ### Google OAuth Implementation
  
  \`\`\`javascript
  const express = require('express');
  const session = require('express-session');
  const passport = require('passport');
  const GoogleStrategy = require('passport-google-oauth20').Strategy;
  const jwt = require('jsonwebtoken');
  
  const app = express();
  
  // Config
  const JWT_SECRET = process.env.JWT_SECRET || 'your-secret-key';
  const GOOGLE_CLIENT_ID = process.env.GOOGLE_CLIENT_ID;
  const GOOGLE_CLIENT_SECRET = process.env.GOOGLE_CLIENT_SECRET;
  const CALLBACK_URL = 'http://localhost:3000/auth/google/callback';
  
  // Session configuration
  app.use(session({
    secret: 'session-secret',
    resave: false,
    saveUninitialized: false
  }));
  
  // Initialize Passport
  app.use(passport.initialize());
  app.use(passport.session());
  
  // Mock user database
  const users = [];
  
  // Passport configuration
  passport.use(new GoogleStrategy({
    clientID: GOOGLE_CLIENT_ID,
    clientSecret: GOOGLE_CLIENT_SECRET,
    callbackURL: CALLBACK_URL,
    scope: ['profile', 'email']
  }, async (accessToken, refreshToken, profile, done) => {
    try {
      // Extract user info from profile
      const email = profile.emails[0].value;
      
      // Find or create user
      let user = users.find(u => u.email === email);
      if (!user) {
        user = {
          id: profile.id,
          email,
          name: profile.displayName,
          picture: profile.photos[0].value,
          roles: ['user'],
          googleId: profile.id,
          createdAt: new Date()
        };
        users.push(user);
      }
      
      return done(null, user);
    } catch (error) {
      return done(error);
    }
  }));
  
  // Serialize and deserialize user
  passport.serializeUser((user, done) => {
    done(null, user.id);
  });
  
  passport.deserializeUser((id, done) => {
    const user = users.find(u => u.id === id);
    done(null, user || null);
  });
  
  // Routes
  app.get('/', (req, res) => {
    res.send(\`
      <h1>OAuth Example</h1>
      <a href="/auth/google">Login with Google</a>
    \`);
  });
  
  // Start Google OAuth flow
  app.get('/auth/google', passport.authenticate('google'));
  
  // Google OAuth callback
  app.get('/auth/google/callback', 
    passport.authenticate('google', { failureRedirect: '/login-failed' }),
    (req, res) => {
      // Generate JWT token
      const payload = {
        sub: req.user.id,
        email: req.user.email,
        name: req.user.name,
        roles: req.user.roles
      };
      
      const token = jwt.sign(payload, JWT_SECRET, { expiresIn: '1h' });
      
      // In production, redirect to frontend with token
      res.send(\`
        <h1>Authentication Successful!</h1>
        <p>Your access token: \${token}</p>
        <script>
          // In production, store token and redirect
          localStorage.setItem('accessToken', '\${token}');
          // window.location = '/dashboard';
        </script>
      \`);
    }
  );
  
  app.get('/login-failed', (req, res) => {
    res.status(401).send('Authentication failed');
  });
  
  app.listen(3000, () => {
    console.log('OAuth server listening on port 3000');
  });
  \`\`\`
  
  ## Multi-Factor Authentication (MFA)
  
  Implementing MFA using time-based one-time passwords (TOTP):
  
  ### TOTP Implementation
  
  \`\`\`javascript
  const express = require('express');
  const jwt = require('jsonwebtoken');
  const bcrypt = require('bcrypt');
  const speakeasy = require('speakeasy');
  const QRCode = require('qrcode');
  
  const app = express();
  app.use(express.json());
  
  // Config
  const JWT_SECRET = process.env.JWT_SECRET || 'your-secret-key';
  const APP_NAME = 'YourApp';
  
  // Mock user database
  const users = [];
  
  // Register new user
  app.post('/register', async (req, res) => {
    const { email, password, name } = req.body;
    
    // Basic validation
    if (!email || !password || !name) {
      return res.status(400).json({ message: 'All fields are required' });
    }
    
    // Check if user already exists
    if (users.find(u => u.email === email)) {
      return res.status(409).json({ message: 'User already exists' });
    }
    
    try {
      // Hash password
      const hashedPassword = await bcrypt.hash(password, 10);
      
      // Create new user
      const newUser = {
        id: Date.now().toString(),
        email,
        password: hashedPassword,
        name,
        roles: ['user'],
        mfaEnabled: false,
        mfaSecret: null,
        createdAt: new Date()
      };
      
      users.push(newUser);
      
      res.status(201).json({
        message: 'User registered successfully',
        userId: newUser.id
      });
    } catch (error) {
      console.error('Registration error:', error);
      res.status(500).json({ message: 'Error registering user' });
    }
  });
  
  // Login (first factor)
  app.post('/login', async (req, res) => {
    const { email, password } = req.body;
    
    // Find user
    const user = users.find(u => u.email === email);
    if (!user) {
      return res.status(401).json({ message: 'Invalid credentials' });
    }
    
    try {
      // Verify password
      const passwordMatch = await bcrypt.compare(password, user.password);
      if (!passwordMatch) {
        return res.status(401).json({ message: 'Invalid credentials' });
      }
      
      // If MFA is not enabled, issue full token
      if (!user.mfaEnabled) {
        const payload = {
          sub: user.id,
          email: user.email,
          name: user.name,
          roles: user.roles
        };
        
        const token = jwt.sign(payload, JWT_SECRET, { expiresIn: '1h' });
        
        return res.json({
          message: 'Login successful',
          accessToken: token,
          mfaRequired: false
        });
      }
      
      // If MFA is enabled, issue pre-auth token
      const preAuthToken = jwt.sign(
        { sub: user.id, preAuth: true },
        JWT_SECRET,
        { expiresIn: '5m' }
      );
      
      res.json({
        message: 'First factor successful',
        preAuthToken,
        mfaRequired: true
      });
    } catch (error) {
      console.error('Login error:', error);
      res.status(500).json({ message: 'Error during login' });
    }
  });
  
  // Setup MFA
  app.post('/mfa/setup', authenticateToken, async (req, res) => {
    try {
      const userId = req.user.sub;
      const user = users.find(u => u.id === userId);
      
      if (!user) {
        return res.status(404).json({ message: 'User not found' });
      }
      
      // Generate new TOTP secret
      const secret = speakeasy.generateSecret({
        name: \`\${APP_NAME}:\${user.email}\`
      });
      
      // Store secret temporarily (don't enable MFA yet)
      user.pendingMfaSecret = secret.base32;
      
      // Generate QR code
      const qrCodeUrl = await QRCode.toDataURL(secret.otpauth_url);
      
      res.json({
        message: 'MFA setup initiated',
        secret: secret.base32,
        qrCode: qrCodeUrl
      });
    } catch (error) {
      console.error('MFA setup error:', error);
      res.status(500).json({ message: 'Error setting up MFA' });
    }
  });
  
  // Verify and enable MFA
  app.post('/mfa/verify', authenticateToken, (req, res) => {
    const { token } = req.body;
    const userId = req.user.sub;
    const user = users.find(u => u.id === userId);
    
    if (!user) {
      return res.status(404).json({ message: 'User not found' });
    }
    
    if (!user.pendingMfaSecret) {
      return res.status(400).json({ message: 'MFA setup not initiated' });
    }
    
    // Verify TOTP token
    const verified = speakeasy.totp.verify({
      secret: user.pendingMfaSecret,
      encoding: 'base32',
      token
    });
    
    if (!verified) {
      return res.status(400).json({ message: 'Invalid verification code' });
    }
    
    // Enable MFA
    user.mfaEnabled = true;
    user.mfaSecret = user.pendingMfaSecret;
    user.pendingMfaSecret = null;
    
    res.json({ message: 'MFA enabled successfully' });
  });
  
  // Verify MFA token (second factor)
  app.post('/mfa/authenticate', (req, res) => {
    const { preAuthToken, token } = req.body;
    
    if (!preAuthToken || !token) {
      return res.status(400).json({ message: 'Both preAuthToken and token are required' });
    }
    
    try {
      // Verify pre-auth token
      const decoded = jwt.verify(preAuthToken, JWT_SECRET);
      if (!decoded.preAuth) {
        return res.status(400).json({ message: 'Invalid pre-auth token' });
      }
      
      // Find user
      const userId = decoded.sub;
      const user = users.find(u => u.id === userId);
      
      if (!user || !user.mfaEnabled) {
        return res.status(400).json({ message: 'MFA not enabled for this user' });
      }
      
      // Verify TOTP token
      const verified = speakeasy.totp.verify({
        secret: user.mfaSecret,
        encoding: 'base32',
        token,
        window: 1 // Allow 1 time step before/after for clock skew
      });
      
      if (!verified) {
        return res.status(400).json({ message: 'Invalid MFA code' });
      }
      
      // Issue full token
      const payload = {
        sub: user.id,
        email: user.email,
        name: user.name,
        roles: user.roles
      };
      
      const accessToken = jwt.sign(payload, JWT_SECRET, { expiresIn: '1h' });
      
      res.json({
        message: 'MFA authentication successful',
        accessToken,
        expiresIn: 3600
      });
    } catch (error) {
      console.error('MFA authentication error:', error);
      res.status(401).json({ message: 'MFA authentication failed' });
    }
  });
  
  // Middleware for authentication
  function authenticateToken(req, res, next) {
    const authHeader = req.headers['authorization'];
    const token = authHeader && authHeader.split(' ')[1];
    
    if (!token) {
      return res.status(401).json({ message: 'Authentication required' });
    }
    
    jwt.verify(token, JWT_SECRET, (err, decoded) => {
      if (err) {
        return res.status(403).json({ message: 'Invalid or expired token' });
      }
      
      req.user = decoded;
      next();
    });
  }
  
  app.listen(3000, () => {
    console.log('MFA auth server listening on port 3000');
  });
  \`\`\`
  
  ## Authentication in Microservices Architecture
  
  In a microservices setup, authentication requires special consideration:
  
  ### API Gateway Authentication
  
  \`\`\`javascript
  // api-gateway.js
  const express = require('express');
  const { createProxyMiddleware } = require('http-proxy-middleware');
  const jwt = require('jsonwebtoken');
  
  const app = express();
  const JWT_SECRET = process.env.JWT_SECRET || 'your-secret-key';
  
  // Authentication middleware
  function authenticateToken(req, res, next) {
    const authHeader = req.headers['authorization'];
    const token = authHeader && authHeader.split(' ')[1];
    
    if (!token) {
      return res.status(401).json({ message: 'Authentication required' });
    }
    
    jwt.verify(token, JWT_SECRET, (err, decoded) => {
      if (err) {
        return res.status(403).json({ message: 'Invalid or expired token' });
      }
      
      // Add user info to request for downstream services
      req.user = decoded;
      
      // Add user info to headers for services
      req.headers['x-user-id'] = decoded.sub;
      req.headers['x-user-roles'] = decoded.roles.join(',');
      
      next();
    });
  }
  
  // Routes that don't require authentication
  app.use('/api/auth', createProxyMiddleware({
    target: 'http://auth-service:3001',
    pathRewrite: {'^/api/auth': '/'},
  }));
  
  // Routes requiring authentication
  app.use('/api/users', authenticateToken, createProxyMiddleware({
    target: 'http://user-service:3002',
    pathRewrite: {'^/api/users': '/'},
  }));
  
  app.use('/api/orders', authenticateToken, createProxyMiddleware({
    target: 'http://order-service:3003',
    pathRewrite: {'^/api/orders': '/'},
  }));
  
  app.listen(3000, () => {
    console.log('API Gateway running on port 3000');
  });
  \`\`\`
  
  ### Backend Service Validation
  
  \`\`\`javascript
  // order-service.js
  const express = require('express');
  const app = express();
  app.use(express.json());
  
  // Validate user from API Gateway headers
  function validateUser(req, res, next) {
    const userId = req.headers['x-user-id'];
    const userRoles = req.headers['x-user-roles'] ? 
      req.headers['x-user-roles'].split(',') : [];
    
    if (!userId) {
      return res.status(401).json({ message: 'User ID header missing' });
    }
    
    req.user = {
      id: userId,
      roles: userRoles
    };
    
    next();
  }
  
  // Apply validation to all routes
  app.use(validateUser);
  
  // Check specific permissions
  function hasRole(roles = []) {
    return (req, res, next) => {
      if (roles.length && !req.user.roles.some(role => roles.includes(role))) {
        return res.status(403).json({ message: 'Insufficient permissions' });
      }
      next();
    };
  }
  
  // Routes
  app.get('/orders', (req, res) => {
    // Return orders for the authenticated user
    res.json({ orders: [] });
  });
  
  app.get('/admin/orders', hasRole(['admin']), (req, res) => {
    // Admin-only endpoint
    res.json({ allOrders: [] });
  });
  
  app.listen(3003, () => {
    console.log('Order service listening on port 3003');
  });
  \`\`\`
  
  ## Security Best Practices for Node.js Authentication
  
  1. **Use HTTPS**: Always serve your auth endpoints over HTTPS
  2. **Implement rate limiting**: Protect against brute force attacks
  3. **Apply proper CORS policies**: Restrict which domains can access your API
  4. **Use secure cookies**: Set the Secure, HttpOnly, and SameSite flags
  5. **Implement proper password policies**: Enforce password complexity
  6. **Add CSRF protection**: For cookie-based authentication
  7. **Securely store secrets**: Use environment variables or a secrets manager
  8. **Implement proper logging**: Log authentication events without sensitive data
  9. **Regular security audits**: Use tools like npm audit to check dependencies
  10. **Implement account lockout**: After multiple failed attempts
  
  ### Implementation Example: Rate Limiting
  
  \`\`\`javascript
  const express = require('express');
  const rateLimit = require('express-rate-limit');
  
  const app = express();
  
  // Apply rate limiting to authentication endpoints
  const authLimiter = rateLimit({
    windowMs: 15 * 60 * 1000, // 15 minutes
    max: 5, // 5 requests per window
    standardHeaders: true,
    legacyHeaders: false,
    message: { message: 'Too many login attempts, please try again later' }
  });
  
  app.use('/login', authLimiter);
  app.use('/register', authLimiter);
  app.use('/reset-password', authLimiter);
  
  // Regular routes...
  
  app.listen(3000);
  \`\`\`
  
  ### Implementation Example: CORS Configuration
  
  \`\`\`javascript
  const express = require('express');
  const cors = require('cors');
  
  const app = express();
  
  // Configure CORS for auth endpoints
  const corsOptions = {
    origin: ['https://yourdomain.com', 'https://app.yourdomain.com'],
    methods: ['GET', 'POST'],
    allowedHeaders: ['Content-Type', 'Authorization'],
    credentials: true,
    maxAge: 86400 // 24 hours
  };
  
  app.use(cors(corsOptions));
  
  // Routes...
  
  app.listen(3000);
  \`\`\`
  
  ## Conclusion: Building a Robust Auth System
  
  Authentication and authorization are critical components of any application's security infrastructure. By implementing modern approaches like JWT-based authentication, passwordless login, OAuth integration, and multi-factor authentication, you can provide both security and a good user experience.
  
  Remember that authentication is an ever-evolving landscape, and what works today may not be sufficient tomorrow. Stay updated with security best practices, regularly audit your auth implementation, and be prepared to adapt as new threats emerge and security standards evolve.
  
  For production applications, consider leveraging battle-tested auth providers like Auth0, Okta, or Firebase Authentication, which can handle many of the security concerns for you while allowing you to focus on your core application logic.
  
  Whatever approach you choose, make security a priority from the beginning of your development process, not an afterthought. Your users trust you with their data - implementing robust authentication and authorization is a key part of honoring that trust.
    `,
    author: "Alex Johnson",
    date: "2025-02-15",
    readTime: 18,
    tags: [
      "Node.js",
      "Authentication",
      "Security",
      "JWT",
      "OAuth",
      "Backend Development",
    ],
    image: "./images/blog/nodejs-auth.png",
    featured: false,
  },
];

export default blogPosts;
